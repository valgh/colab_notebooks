{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformer_encodings_cfg_asm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOL3G1y2Sd6PHwpxbYs9qk5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valgh/colab_notebooks/blob/main/transformer_encodings_cfg_asm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrIxykBejt0v",
        "outputId": "1fa5365a-81bb-45a0-c229-8d2d33f8b237",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# now we can start working with our dataset.\n",
        "# mounting drive...\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive/\", force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRmirT-Dj16T",
        "outputId": "bb274297-5397-49e3-dbf0-49b75d03dbf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import json\n",
        "randwalks_seq = json.load(open(\"/content/gdrive/My Drive/randwalk_text_embedded_10000.json\", \"r\"))\n",
        "num_samples = len(randwalks_seq)\n",
        "print(num_samples)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0Silaevj3Nt",
        "outputId": "6b53a782-4309-462c-ee38-5b6245b5ff78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  ['10.58.225.154:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.58.225.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.58.225.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Smi8t8C2j8mf",
        "outputId": "c811d84a-3775-48a8-ccac-6117e184a189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "# importing punkt from nltk \n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2liZ7qikApv",
        "outputId": "030b04b1-fc2f-44be-f934-62cfa394ba73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# DATASET PREPROCESSING STEP\n",
        "\n",
        "# something else we should do is filter out same randwalks. We just need to keep,\n",
        "# for each function, the randwalks that are different one from another, and discard\n",
        "# the 'duplicates'.\n",
        "\n",
        "# There is also something else we should apply here: STEMMING om the functions names,\n",
        "# and then filtering out all those tokens that just represent an identifier for \n",
        "# the software (\"gsl\", \"gl\", \"gnu\", see IN NOMINE FUNCTION paper chapter 4).\n",
        "\n",
        "from nltk.stem import PorterStemmer \n",
        "from nltk.tokenize import word_tokenize \n",
        "\n",
        "# Maximum number of samples to preprocess\n",
        "MAX_SAMPLES = 10000\n",
        "\n",
        "def create_token_selection(randwalks_seq):\n",
        "  out = {}\n",
        "  stemmer = PorterStemmer()\n",
        "  for name in randwalks_seq:\n",
        "    # same preprocessing sytep as reported below\n",
        "    name = name.strip()\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "    name = re.sub(r\"([?.!,])\", r\" \\1 \", name)\n",
        "    name = re.sub(r'[\" \"]+', \" \", name)\n",
        "    # replacing everything with space except (a-z, A-Z, 0-9)\n",
        "    name = re.sub(r\"[^a-zA-Z0-9]+\", \" \", name)\n",
        "    name = re.sub(r\"([A-Z])\", r\" \\1\", name)\n",
        "    tokens = word_tokenize(name)\n",
        "    for token in tokens:\n",
        "      stemmed_token = stemmer.stem(token)\n",
        "      if stemmed_token in out:\n",
        "        out[stemmed_token] += 1\n",
        "      else:\n",
        "        out[stemmed_token] = 1\n",
        "  return out\n",
        "\n",
        "def stem_and_filter_tokens(sentence, token_selection):\n",
        "  stemmer = PorterStemmer()\n",
        "  tokens = word_tokenize(sentence)\n",
        "  threshold = 50\n",
        "  out = \"\"\n",
        "  for token in tokens:\n",
        "    stemmed_token = stemmer.stem(token)\n",
        "    if token_selection[stemmed_token] > threshold:\n",
        "      out += \" \"+stemmed_token\n",
        "  return out\n",
        "\n",
        "def preprocess_seq(sentence, is_name, token_selection):\n",
        "  sentence = sentence.strip()\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "  # replacing everything with space except (a-z, A-Z, 0-9)\n",
        "  sentence = re.sub(r\"[^a-zA-Z0-9]+\", \" \", sentence)\n",
        "  if is_name == True:\n",
        "    # place a space between lower and upper case letter -> \"getCommand\" ---> \"get Command\"\n",
        "    sentence = re.sub(r\"([A-Z])\", r\" \\1\", sentence)\n",
        "    sentence = stem_and_filter_tokens(sentence, token_selection)\n",
        "  sentence = sentence.strip()\n",
        "  # adding a start and an end token to the sentence\n",
        "  return sentence\n",
        "\n",
        "\n",
        "def load_dataset(randwalks_seq, MAX_SAMPLES, token_selection):\n",
        "  # dictionary of name to string sequences\n",
        "  check = {}\n",
        "  names = []\n",
        "  sequences = []\n",
        "  counter = 0\n",
        "  for name in randwalks_seq:\n",
        "    counter+=1\n",
        "    print(counter)\n",
        "    if counter == MAX_SAMPLES:\n",
        "      break\n",
        "    preprocessed_name = preprocess_seq(name, True, token_selection)\n",
        "    check[preprocessed_name] = {}\n",
        "    for seq in randwalks_seq[name]:\n",
        "      for l in randwalks_seq[name][seq]:\n",
        "        seq_as_str = \"\"\n",
        "        for el in l:\n",
        "          preprocessed_seq = preprocess_seq(el, False, token_selection)\n",
        "          seq_as_str += \" \"+preprocessed_seq\n",
        "        if seq_as_str not in check[preprocessed_name]:\n",
        "          check[preprocessed_name][seq_as_str] = 0\n",
        "          names.append(preprocessed_name)\n",
        "          sequences.append(seq_as_str)\n",
        "  return names, sequences\n",
        "\n",
        "token_selection = create_token_selection(randwalks_seq)\n",
        "print(len(token_selection))\n",
        "names, sequences = load_dataset(randwalks_seq, MAX_SAMPLES, token_selection)\n",
        "\n",
        "print(len(sequences))\n",
        "\n",
        "print('Sample function name: {}'.format(names[120]))\n",
        "print('Sample sequence: {}'.format(sequences[120]))\n",
        "\n",
        "#  now splitting dataset into train and test sets\n",
        "\n",
        "# now we split our dataset into train, development and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "rest_seq, test_seq, rest_names, test_names = train_test_split(sequences, names, test_size=0.05, random_state=1)\n",
        "train_seq, dev_seq, train_names, dev_names = train_test_split(rest_seq, rest_names, test_size=0.05, random_state=1)\n",
        "\n",
        "print(\"Train size:\", len(train_seq))\n",
        "print(\"Dev size:\", len(dev_seq)) #not actually used here\n",
        "print(\"Test size:\", len(test_seq))\n",
        "\n",
        "sequences = train_seq + dev_seq\n",
        "names = train_names + dev_names\n",
        "\n",
        "print(len(sequences))\n",
        "print(len(names))\n",
        "print(len(test_seq))\n",
        "print(len(test_names))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mOutput streaming troncato alle ultime 5000 righe.\u001b[0m\n",
            "5012\n",
            "5013\n",
            "5014\n",
            "5015\n",
            "5016\n",
            "5017\n",
            "5018\n",
            "5019\n",
            "5020\n",
            "5021\n",
            "5022\n",
            "5023\n",
            "5024\n",
            "5025\n",
            "5026\n",
            "5027\n",
            "5028\n",
            "5029\n",
            "5030\n",
            "5031\n",
            "5032\n",
            "5033\n",
            "5034\n",
            "5035\n",
            "5036\n",
            "5037\n",
            "5038\n",
            "5039\n",
            "5040\n",
            "5041\n",
            "5042\n",
            "5043\n",
            "5044\n",
            "5045\n",
            "5046\n",
            "5047\n",
            "5048\n",
            "5049\n",
            "5050\n",
            "5051\n",
            "5052\n",
            "5053\n",
            "5054\n",
            "5055\n",
            "5056\n",
            "5057\n",
            "5058\n",
            "5059\n",
            "5060\n",
            "5061\n",
            "5062\n",
            "5063\n",
            "5064\n",
            "5065\n",
            "5066\n",
            "5067\n",
            "5068\n",
            "5069\n",
            "5070\n",
            "5071\n",
            "5072\n",
            "5073\n",
            "5074\n",
            "5075\n",
            "5076\n",
            "5077\n",
            "5078\n",
            "5079\n",
            "5080\n",
            "5081\n",
            "5082\n",
            "5083\n",
            "5084\n",
            "5085\n",
            "5086\n",
            "5087\n",
            "5088\n",
            "5089\n",
            "5090\n",
            "5091\n",
            "5092\n",
            "5093\n",
            "5094\n",
            "5095\n",
            "5096\n",
            "5097\n",
            "5098\n",
            "5099\n",
            "5100\n",
            "5101\n",
            "5102\n",
            "5103\n",
            "5104\n",
            "5105\n",
            "5106\n",
            "5107\n",
            "5108\n",
            "5109\n",
            "5110\n",
            "5111\n",
            "5112\n",
            "5113\n",
            "5114\n",
            "5115\n",
            "5116\n",
            "5117\n",
            "5118\n",
            "5119\n",
            "5120\n",
            "5121\n",
            "5122\n",
            "5123\n",
            "5124\n",
            "5125\n",
            "5126\n",
            "5127\n",
            "5128\n",
            "5129\n",
            "5130\n",
            "5131\n",
            "5132\n",
            "5133\n",
            "5134\n",
            "5135\n",
            "5136\n",
            "5137\n",
            "5138\n",
            "5139\n",
            "5140\n",
            "5141\n",
            "5142\n",
            "5143\n",
            "5144\n",
            "5145\n",
            "5146\n",
            "5147\n",
            "5148\n",
            "5149\n",
            "5150\n",
            "5151\n",
            "5152\n",
            "5153\n",
            "5154\n",
            "5155\n",
            "5156\n",
            "5157\n",
            "5158\n",
            "5159\n",
            "5160\n",
            "5161\n",
            "5162\n",
            "5163\n",
            "5164\n",
            "5165\n",
            "5166\n",
            "5167\n",
            "5168\n",
            "5169\n",
            "5170\n",
            "5171\n",
            "5172\n",
            "5173\n",
            "5174\n",
            "5175\n",
            "5176\n",
            "5177\n",
            "5178\n",
            "5179\n",
            "5180\n",
            "5181\n",
            "5182\n",
            "5183\n",
            "5184\n",
            "5185\n",
            "5186\n",
            "5187\n",
            "5188\n",
            "5189\n",
            "5190\n",
            "5191\n",
            "5192\n",
            "5193\n",
            "5194\n",
            "5195\n",
            "5196\n",
            "5197\n",
            "5198\n",
            "5199\n",
            "5200\n",
            "5201\n",
            "5202\n",
            "5203\n",
            "5204\n",
            "5205\n",
            "5206\n",
            "5207\n",
            "5208\n",
            "5209\n",
            "5210\n",
            "5211\n",
            "5212\n",
            "5213\n",
            "5214\n",
            "5215\n",
            "5216\n",
            "5217\n",
            "5218\n",
            "5219\n",
            "5220\n",
            "5221\n",
            "5222\n",
            "5223\n",
            "5224\n",
            "5225\n",
            "5226\n",
            "5227\n",
            "5228\n",
            "5229\n",
            "5230\n",
            "5231\n",
            "5232\n",
            "5233\n",
            "5234\n",
            "5235\n",
            "5236\n",
            "5237\n",
            "5238\n",
            "5239\n",
            "5240\n",
            "5241\n",
            "5242\n",
            "5243\n",
            "5244\n",
            "5245\n",
            "5246\n",
            "5247\n",
            "5248\n",
            "5249\n",
            "5250\n",
            "5251\n",
            "5252\n",
            "5253\n",
            "5254\n",
            "5255\n",
            "5256\n",
            "5257\n",
            "5258\n",
            "5259\n",
            "5260\n",
            "5261\n",
            "5262\n",
            "5263\n",
            "5264\n",
            "5265\n",
            "5266\n",
            "5267\n",
            "5268\n",
            "5269\n",
            "5270\n",
            "5271\n",
            "5272\n",
            "5273\n",
            "5274\n",
            "5275\n",
            "5276\n",
            "5277\n",
            "5278\n",
            "5279\n",
            "5280\n",
            "5281\n",
            "5282\n",
            "5283\n",
            "5284\n",
            "5285\n",
            "5286\n",
            "5287\n",
            "5288\n",
            "5289\n",
            "5290\n",
            "5291\n",
            "5292\n",
            "5293\n",
            "5294\n",
            "5295\n",
            "5296\n",
            "5297\n",
            "5298\n",
            "5299\n",
            "5300\n",
            "5301\n",
            "5302\n",
            "5303\n",
            "5304\n",
            "5305\n",
            "5306\n",
            "5307\n",
            "5308\n",
            "5309\n",
            "5310\n",
            "5311\n",
            "5312\n",
            "5313\n",
            "5314\n",
            "5315\n",
            "5316\n",
            "5317\n",
            "5318\n",
            "5319\n",
            "5320\n",
            "5321\n",
            "5322\n",
            "5323\n",
            "5324\n",
            "5325\n",
            "5326\n",
            "5327\n",
            "5328\n",
            "5329\n",
            "5330\n",
            "5331\n",
            "5332\n",
            "5333\n",
            "5334\n",
            "5335\n",
            "5336\n",
            "5337\n",
            "5338\n",
            "5339\n",
            "5340\n",
            "5341\n",
            "5342\n",
            "5343\n",
            "5344\n",
            "5345\n",
            "5346\n",
            "5347\n",
            "5348\n",
            "5349\n",
            "5350\n",
            "5351\n",
            "5352\n",
            "5353\n",
            "5354\n",
            "5355\n",
            "5356\n",
            "5357\n",
            "5358\n",
            "5359\n",
            "5360\n",
            "5361\n",
            "5362\n",
            "5363\n",
            "5364\n",
            "5365\n",
            "5366\n",
            "5367\n",
            "5368\n",
            "5369\n",
            "5370\n",
            "5371\n",
            "5372\n",
            "5373\n",
            "5374\n",
            "5375\n",
            "5376\n",
            "5377\n",
            "5378\n",
            "5379\n",
            "5380\n",
            "5381\n",
            "5382\n",
            "5383\n",
            "5384\n",
            "5385\n",
            "5386\n",
            "5387\n",
            "5388\n",
            "5389\n",
            "5390\n",
            "5391\n",
            "5392\n",
            "5393\n",
            "5394\n",
            "5395\n",
            "5396\n",
            "5397\n",
            "5398\n",
            "5399\n",
            "5400\n",
            "5401\n",
            "5402\n",
            "5403\n",
            "5404\n",
            "5405\n",
            "5406\n",
            "5407\n",
            "5408\n",
            "5409\n",
            "5410\n",
            "5411\n",
            "5412\n",
            "5413\n",
            "5414\n",
            "5415\n",
            "5416\n",
            "5417\n",
            "5418\n",
            "5419\n",
            "5420\n",
            "5421\n",
            "5422\n",
            "5423\n",
            "5424\n",
            "5425\n",
            "5426\n",
            "5427\n",
            "5428\n",
            "5429\n",
            "5430\n",
            "5431\n",
            "5432\n",
            "5433\n",
            "5434\n",
            "5435\n",
            "5436\n",
            "5437\n",
            "5438\n",
            "5439\n",
            "5440\n",
            "5441\n",
            "5442\n",
            "5443\n",
            "5444\n",
            "5445\n",
            "5446\n",
            "5447\n",
            "5448\n",
            "5449\n",
            "5450\n",
            "5451\n",
            "5452\n",
            "5453\n",
            "5454\n",
            "5455\n",
            "5456\n",
            "5457\n",
            "5458\n",
            "5459\n",
            "5460\n",
            "5461\n",
            "5462\n",
            "5463\n",
            "5464\n",
            "5465\n",
            "5466\n",
            "5467\n",
            "5468\n",
            "5469\n",
            "5470\n",
            "5471\n",
            "5472\n",
            "5473\n",
            "5474\n",
            "5475\n",
            "5476\n",
            "5477\n",
            "5478\n",
            "5479\n",
            "5480\n",
            "5481\n",
            "5482\n",
            "5483\n",
            "5484\n",
            "5485\n",
            "5486\n",
            "5487\n",
            "5488\n",
            "5489\n",
            "5490\n",
            "5491\n",
            "5492\n",
            "5493\n",
            "5494\n",
            "5495\n",
            "5496\n",
            "5497\n",
            "5498\n",
            "5499\n",
            "5500\n",
            "5501\n",
            "5502\n",
            "5503\n",
            "5504\n",
            "5505\n",
            "5506\n",
            "5507\n",
            "5508\n",
            "5509\n",
            "5510\n",
            "5511\n",
            "5512\n",
            "5513\n",
            "5514\n",
            "5515\n",
            "5516\n",
            "5517\n",
            "5518\n",
            "5519\n",
            "5520\n",
            "5521\n",
            "5522\n",
            "5523\n",
            "5524\n",
            "5525\n",
            "5526\n",
            "5527\n",
            "5528\n",
            "5529\n",
            "5530\n",
            "5531\n",
            "5532\n",
            "5533\n",
            "5534\n",
            "5535\n",
            "5536\n",
            "5537\n",
            "5538\n",
            "5539\n",
            "5540\n",
            "5541\n",
            "5542\n",
            "5543\n",
            "5544\n",
            "5545\n",
            "5546\n",
            "5547\n",
            "5548\n",
            "5549\n",
            "5550\n",
            "5551\n",
            "5552\n",
            "5553\n",
            "5554\n",
            "5555\n",
            "5556\n",
            "5557\n",
            "5558\n",
            "5559\n",
            "5560\n",
            "5561\n",
            "5562\n",
            "5563\n",
            "5564\n",
            "5565\n",
            "5566\n",
            "5567\n",
            "5568\n",
            "5569\n",
            "5570\n",
            "5571\n",
            "5572\n",
            "5573\n",
            "5574\n",
            "5575\n",
            "5576\n",
            "5577\n",
            "5578\n",
            "5579\n",
            "5580\n",
            "5581\n",
            "5582\n",
            "5583\n",
            "5584\n",
            "5585\n",
            "5586\n",
            "5587\n",
            "5588\n",
            "5589\n",
            "5590\n",
            "5591\n",
            "5592\n",
            "5593\n",
            "5594\n",
            "5595\n",
            "5596\n",
            "5597\n",
            "5598\n",
            "5599\n",
            "5600\n",
            "5601\n",
            "5602\n",
            "5603\n",
            "5604\n",
            "5605\n",
            "5606\n",
            "5607\n",
            "5608\n",
            "5609\n",
            "5610\n",
            "5611\n",
            "5612\n",
            "5613\n",
            "5614\n",
            "5615\n",
            "5616\n",
            "5617\n",
            "5618\n",
            "5619\n",
            "5620\n",
            "5621\n",
            "5622\n",
            "5623\n",
            "5624\n",
            "5625\n",
            "5626\n",
            "5627\n",
            "5628\n",
            "5629\n",
            "5630\n",
            "5631\n",
            "5632\n",
            "5633\n",
            "5634\n",
            "5635\n",
            "5636\n",
            "5637\n",
            "5638\n",
            "5639\n",
            "5640\n",
            "5641\n",
            "5642\n",
            "5643\n",
            "5644\n",
            "5645\n",
            "5646\n",
            "5647\n",
            "5648\n",
            "5649\n",
            "5650\n",
            "5651\n",
            "5652\n",
            "5653\n",
            "5654\n",
            "5655\n",
            "5656\n",
            "5657\n",
            "5658\n",
            "5659\n",
            "5660\n",
            "5661\n",
            "5662\n",
            "5663\n",
            "5664\n",
            "5665\n",
            "5666\n",
            "5667\n",
            "5668\n",
            "5669\n",
            "5670\n",
            "5671\n",
            "5672\n",
            "5673\n",
            "5674\n",
            "5675\n",
            "5676\n",
            "5677\n",
            "5678\n",
            "5679\n",
            "5680\n",
            "5681\n",
            "5682\n",
            "5683\n",
            "5684\n",
            "5685\n",
            "5686\n",
            "5687\n",
            "5688\n",
            "5689\n",
            "5690\n",
            "5691\n",
            "5692\n",
            "5693\n",
            "5694\n",
            "5695\n",
            "5696\n",
            "5697\n",
            "5698\n",
            "5699\n",
            "5700\n",
            "5701\n",
            "5702\n",
            "5703\n",
            "5704\n",
            "5705\n",
            "5706\n",
            "5707\n",
            "5708\n",
            "5709\n",
            "5710\n",
            "5711\n",
            "5712\n",
            "5713\n",
            "5714\n",
            "5715\n",
            "5716\n",
            "5717\n",
            "5718\n",
            "5719\n",
            "5720\n",
            "5721\n",
            "5722\n",
            "5723\n",
            "5724\n",
            "5725\n",
            "5726\n",
            "5727\n",
            "5728\n",
            "5729\n",
            "5730\n",
            "5731\n",
            "5732\n",
            "5733\n",
            "5734\n",
            "5735\n",
            "5736\n",
            "5737\n",
            "5738\n",
            "5739\n",
            "5740\n",
            "5741\n",
            "5742\n",
            "5743\n",
            "5744\n",
            "5745\n",
            "5746\n",
            "5747\n",
            "5748\n",
            "5749\n",
            "5750\n",
            "5751\n",
            "5752\n",
            "5753\n",
            "5754\n",
            "5755\n",
            "5756\n",
            "5757\n",
            "5758\n",
            "5759\n",
            "5760\n",
            "5761\n",
            "5762\n",
            "5763\n",
            "5764\n",
            "5765\n",
            "5766\n",
            "5767\n",
            "5768\n",
            "5769\n",
            "5770\n",
            "5771\n",
            "5772\n",
            "5773\n",
            "5774\n",
            "5775\n",
            "5776\n",
            "5777\n",
            "5778\n",
            "5779\n",
            "5780\n",
            "5781\n",
            "5782\n",
            "5783\n",
            "5784\n",
            "5785\n",
            "5786\n",
            "5787\n",
            "5788\n",
            "5789\n",
            "5790\n",
            "5791\n",
            "5792\n",
            "5793\n",
            "5794\n",
            "5795\n",
            "5796\n",
            "5797\n",
            "5798\n",
            "5799\n",
            "5800\n",
            "5801\n",
            "5802\n",
            "5803\n",
            "5804\n",
            "5805\n",
            "5806\n",
            "5807\n",
            "5808\n",
            "5809\n",
            "5810\n",
            "5811\n",
            "5812\n",
            "5813\n",
            "5814\n",
            "5815\n",
            "5816\n",
            "5817\n",
            "5818\n",
            "5819\n",
            "5820\n",
            "5821\n",
            "5822\n",
            "5823\n",
            "5824\n",
            "5825\n",
            "5826\n",
            "5827\n",
            "5828\n",
            "5829\n",
            "5830\n",
            "5831\n",
            "5832\n",
            "5833\n",
            "5834\n",
            "5835\n",
            "5836\n",
            "5837\n",
            "5838\n",
            "5839\n",
            "5840\n",
            "5841\n",
            "5842\n",
            "5843\n",
            "5844\n",
            "5845\n",
            "5846\n",
            "5847\n",
            "5848\n",
            "5849\n",
            "5850\n",
            "5851\n",
            "5852\n",
            "5853\n",
            "5854\n",
            "5855\n",
            "5856\n",
            "5857\n",
            "5858\n",
            "5859\n",
            "5860\n",
            "5861\n",
            "5862\n",
            "5863\n",
            "5864\n",
            "5865\n",
            "5866\n",
            "5867\n",
            "5868\n",
            "5869\n",
            "5870\n",
            "5871\n",
            "5872\n",
            "5873\n",
            "5874\n",
            "5875\n",
            "5876\n",
            "5877\n",
            "5878\n",
            "5879\n",
            "5880\n",
            "5881\n",
            "5882\n",
            "5883\n",
            "5884\n",
            "5885\n",
            "5886\n",
            "5887\n",
            "5888\n",
            "5889\n",
            "5890\n",
            "5891\n",
            "5892\n",
            "5893\n",
            "5894\n",
            "5895\n",
            "5896\n",
            "5897\n",
            "5898\n",
            "5899\n",
            "5900\n",
            "5901\n",
            "5902\n",
            "5903\n",
            "5904\n",
            "5905\n",
            "5906\n",
            "5907\n",
            "5908\n",
            "5909\n",
            "5910\n",
            "5911\n",
            "5912\n",
            "5913\n",
            "5914\n",
            "5915\n",
            "5916\n",
            "5917\n",
            "5918\n",
            "5919\n",
            "5920\n",
            "5921\n",
            "5922\n",
            "5923\n",
            "5924\n",
            "5925\n",
            "5926\n",
            "5927\n",
            "5928\n",
            "5929\n",
            "5930\n",
            "5931\n",
            "5932\n",
            "5933\n",
            "5934\n",
            "5935\n",
            "5936\n",
            "5937\n",
            "5938\n",
            "5939\n",
            "5940\n",
            "5941\n",
            "5942\n",
            "5943\n",
            "5944\n",
            "5945\n",
            "5946\n",
            "5947\n",
            "5948\n",
            "5949\n",
            "5950\n",
            "5951\n",
            "5952\n",
            "5953\n",
            "5954\n",
            "5955\n",
            "5956\n",
            "5957\n",
            "5958\n",
            "5959\n",
            "5960\n",
            "5961\n",
            "5962\n",
            "5963\n",
            "5964\n",
            "5965\n",
            "5966\n",
            "5967\n",
            "5968\n",
            "5969\n",
            "5970\n",
            "5971\n",
            "5972\n",
            "5973\n",
            "5974\n",
            "5975\n",
            "5976\n",
            "5977\n",
            "5978\n",
            "5979\n",
            "5980\n",
            "5981\n",
            "5982\n",
            "5983\n",
            "5984\n",
            "5985\n",
            "5986\n",
            "5987\n",
            "5988\n",
            "5989\n",
            "5990\n",
            "5991\n",
            "5992\n",
            "5993\n",
            "5994\n",
            "5995\n",
            "5996\n",
            "5997\n",
            "5998\n",
            "5999\n",
            "6000\n",
            "6001\n",
            "6002\n",
            "6003\n",
            "6004\n",
            "6005\n",
            "6006\n",
            "6007\n",
            "6008\n",
            "6009\n",
            "6010\n",
            "6011\n",
            "6012\n",
            "6013\n",
            "6014\n",
            "6015\n",
            "6016\n",
            "6017\n",
            "6018\n",
            "6019\n",
            "6020\n",
            "6021\n",
            "6022\n",
            "6023\n",
            "6024\n",
            "6025\n",
            "6026\n",
            "6027\n",
            "6028\n",
            "6029\n",
            "6030\n",
            "6031\n",
            "6032\n",
            "6033\n",
            "6034\n",
            "6035\n",
            "6036\n",
            "6037\n",
            "6038\n",
            "6039\n",
            "6040\n",
            "6041\n",
            "6042\n",
            "6043\n",
            "6044\n",
            "6045\n",
            "6046\n",
            "6047\n",
            "6048\n",
            "6049\n",
            "6050\n",
            "6051\n",
            "6052\n",
            "6053\n",
            "6054\n",
            "6055\n",
            "6056\n",
            "6057\n",
            "6058\n",
            "6059\n",
            "6060\n",
            "6061\n",
            "6062\n",
            "6063\n",
            "6064\n",
            "6065\n",
            "6066\n",
            "6067\n",
            "6068\n",
            "6069\n",
            "6070\n",
            "6071\n",
            "6072\n",
            "6073\n",
            "6074\n",
            "6075\n",
            "6076\n",
            "6077\n",
            "6078\n",
            "6079\n",
            "6080\n",
            "6081\n",
            "6082\n",
            "6083\n",
            "6084\n",
            "6085\n",
            "6086\n",
            "6087\n",
            "6088\n",
            "6089\n",
            "6090\n",
            "6091\n",
            "6092\n",
            "6093\n",
            "6094\n",
            "6095\n",
            "6096\n",
            "6097\n",
            "6098\n",
            "6099\n",
            "6100\n",
            "6101\n",
            "6102\n",
            "6103\n",
            "6104\n",
            "6105\n",
            "6106\n",
            "6107\n",
            "6108\n",
            "6109\n",
            "6110\n",
            "6111\n",
            "6112\n",
            "6113\n",
            "6114\n",
            "6115\n",
            "6116\n",
            "6117\n",
            "6118\n",
            "6119\n",
            "6120\n",
            "6121\n",
            "6122\n",
            "6123\n",
            "6124\n",
            "6125\n",
            "6126\n",
            "6127\n",
            "6128\n",
            "6129\n",
            "6130\n",
            "6131\n",
            "6132\n",
            "6133\n",
            "6134\n",
            "6135\n",
            "6136\n",
            "6137\n",
            "6138\n",
            "6139\n",
            "6140\n",
            "6141\n",
            "6142\n",
            "6143\n",
            "6144\n",
            "6145\n",
            "6146\n",
            "6147\n",
            "6148\n",
            "6149\n",
            "6150\n",
            "6151\n",
            "6152\n",
            "6153\n",
            "6154\n",
            "6155\n",
            "6156\n",
            "6157\n",
            "6158\n",
            "6159\n",
            "6160\n",
            "6161\n",
            "6162\n",
            "6163\n",
            "6164\n",
            "6165\n",
            "6166\n",
            "6167\n",
            "6168\n",
            "6169\n",
            "6170\n",
            "6171\n",
            "6172\n",
            "6173\n",
            "6174\n",
            "6175\n",
            "6176\n",
            "6177\n",
            "6178\n",
            "6179\n",
            "6180\n",
            "6181\n",
            "6182\n",
            "6183\n",
            "6184\n",
            "6185\n",
            "6186\n",
            "6187\n",
            "6188\n",
            "6189\n",
            "6190\n",
            "6191\n",
            "6192\n",
            "6193\n",
            "6194\n",
            "6195\n",
            "6196\n",
            "6197\n",
            "6198\n",
            "6199\n",
            "6200\n",
            "6201\n",
            "6202\n",
            "6203\n",
            "6204\n",
            "6205\n",
            "6206\n",
            "6207\n",
            "6208\n",
            "6209\n",
            "6210\n",
            "6211\n",
            "6212\n",
            "6213\n",
            "6214\n",
            "6215\n",
            "6216\n",
            "6217\n",
            "6218\n",
            "6219\n",
            "6220\n",
            "6221\n",
            "6222\n",
            "6223\n",
            "6224\n",
            "6225\n",
            "6226\n",
            "6227\n",
            "6228\n",
            "6229\n",
            "6230\n",
            "6231\n",
            "6232\n",
            "6233\n",
            "6234\n",
            "6235\n",
            "6236\n",
            "6237\n",
            "6238\n",
            "6239\n",
            "6240\n",
            "6241\n",
            "6242\n",
            "6243\n",
            "6244\n",
            "6245\n",
            "6246\n",
            "6247\n",
            "6248\n",
            "6249\n",
            "6250\n",
            "6251\n",
            "6252\n",
            "6253\n",
            "6254\n",
            "6255\n",
            "6256\n",
            "6257\n",
            "6258\n",
            "6259\n",
            "6260\n",
            "6261\n",
            "6262\n",
            "6263\n",
            "6264\n",
            "6265\n",
            "6266\n",
            "6267\n",
            "6268\n",
            "6269\n",
            "6270\n",
            "6271\n",
            "6272\n",
            "6273\n",
            "6274\n",
            "6275\n",
            "6276\n",
            "6277\n",
            "6278\n",
            "6279\n",
            "6280\n",
            "6281\n",
            "6282\n",
            "6283\n",
            "6284\n",
            "6285\n",
            "6286\n",
            "6287\n",
            "6288\n",
            "6289\n",
            "6290\n",
            "6291\n",
            "6292\n",
            "6293\n",
            "6294\n",
            "6295\n",
            "6296\n",
            "6297\n",
            "6298\n",
            "6299\n",
            "6300\n",
            "6301\n",
            "6302\n",
            "6303\n",
            "6304\n",
            "6305\n",
            "6306\n",
            "6307\n",
            "6308\n",
            "6309\n",
            "6310\n",
            "6311\n",
            "6312\n",
            "6313\n",
            "6314\n",
            "6315\n",
            "6316\n",
            "6317\n",
            "6318\n",
            "6319\n",
            "6320\n",
            "6321\n",
            "6322\n",
            "6323\n",
            "6324\n",
            "6325\n",
            "6326\n",
            "6327\n",
            "6328\n",
            "6329\n",
            "6330\n",
            "6331\n",
            "6332\n",
            "6333\n",
            "6334\n",
            "6335\n",
            "6336\n",
            "6337\n",
            "6338\n",
            "6339\n",
            "6340\n",
            "6341\n",
            "6342\n",
            "6343\n",
            "6344\n",
            "6345\n",
            "6346\n",
            "6347\n",
            "6348\n",
            "6349\n",
            "6350\n",
            "6351\n",
            "6352\n",
            "6353\n",
            "6354\n",
            "6355\n",
            "6356\n",
            "6357\n",
            "6358\n",
            "6359\n",
            "6360\n",
            "6361\n",
            "6362\n",
            "6363\n",
            "6364\n",
            "6365\n",
            "6366\n",
            "6367\n",
            "6368\n",
            "6369\n",
            "6370\n",
            "6371\n",
            "6372\n",
            "6373\n",
            "6374\n",
            "6375\n",
            "6376\n",
            "6377\n",
            "6378\n",
            "6379\n",
            "6380\n",
            "6381\n",
            "6382\n",
            "6383\n",
            "6384\n",
            "6385\n",
            "6386\n",
            "6387\n",
            "6388\n",
            "6389\n",
            "6390\n",
            "6391\n",
            "6392\n",
            "6393\n",
            "6394\n",
            "6395\n",
            "6396\n",
            "6397\n",
            "6398\n",
            "6399\n",
            "6400\n",
            "6401\n",
            "6402\n",
            "6403\n",
            "6404\n",
            "6405\n",
            "6406\n",
            "6407\n",
            "6408\n",
            "6409\n",
            "6410\n",
            "6411\n",
            "6412\n",
            "6413\n",
            "6414\n",
            "6415\n",
            "6416\n",
            "6417\n",
            "6418\n",
            "6419\n",
            "6420\n",
            "6421\n",
            "6422\n",
            "6423\n",
            "6424\n",
            "6425\n",
            "6426\n",
            "6427\n",
            "6428\n",
            "6429\n",
            "6430\n",
            "6431\n",
            "6432\n",
            "6433\n",
            "6434\n",
            "6435\n",
            "6436\n",
            "6437\n",
            "6438\n",
            "6439\n",
            "6440\n",
            "6441\n",
            "6442\n",
            "6443\n",
            "6444\n",
            "6445\n",
            "6446\n",
            "6447\n",
            "6448\n",
            "6449\n",
            "6450\n",
            "6451\n",
            "6452\n",
            "6453\n",
            "6454\n",
            "6455\n",
            "6456\n",
            "6457\n",
            "6458\n",
            "6459\n",
            "6460\n",
            "6461\n",
            "6462\n",
            "6463\n",
            "6464\n",
            "6465\n",
            "6466\n",
            "6467\n",
            "6468\n",
            "6469\n",
            "6470\n",
            "6471\n",
            "6472\n",
            "6473\n",
            "6474\n",
            "6475\n",
            "6476\n",
            "6477\n",
            "6478\n",
            "6479\n",
            "6480\n",
            "6481\n",
            "6482\n",
            "6483\n",
            "6484\n",
            "6485\n",
            "6486\n",
            "6487\n",
            "6488\n",
            "6489\n",
            "6490\n",
            "6491\n",
            "6492\n",
            "6493\n",
            "6494\n",
            "6495\n",
            "6496\n",
            "6497\n",
            "6498\n",
            "6499\n",
            "6500\n",
            "6501\n",
            "6502\n",
            "6503\n",
            "6504\n",
            "6505\n",
            "6506\n",
            "6507\n",
            "6508\n",
            "6509\n",
            "6510\n",
            "6511\n",
            "6512\n",
            "6513\n",
            "6514\n",
            "6515\n",
            "6516\n",
            "6517\n",
            "6518\n",
            "6519\n",
            "6520\n",
            "6521\n",
            "6522\n",
            "6523\n",
            "6524\n",
            "6525\n",
            "6526\n",
            "6527\n",
            "6528\n",
            "6529\n",
            "6530\n",
            "6531\n",
            "6532\n",
            "6533\n",
            "6534\n",
            "6535\n",
            "6536\n",
            "6537\n",
            "6538\n",
            "6539\n",
            "6540\n",
            "6541\n",
            "6542\n",
            "6543\n",
            "6544\n",
            "6545\n",
            "6546\n",
            "6547\n",
            "6548\n",
            "6549\n",
            "6550\n",
            "6551\n",
            "6552\n",
            "6553\n",
            "6554\n",
            "6555\n",
            "6556\n",
            "6557\n",
            "6558\n",
            "6559\n",
            "6560\n",
            "6561\n",
            "6562\n",
            "6563\n",
            "6564\n",
            "6565\n",
            "6566\n",
            "6567\n",
            "6568\n",
            "6569\n",
            "6570\n",
            "6571\n",
            "6572\n",
            "6573\n",
            "6574\n",
            "6575\n",
            "6576\n",
            "6577\n",
            "6578\n",
            "6579\n",
            "6580\n",
            "6581\n",
            "6582\n",
            "6583\n",
            "6584\n",
            "6585\n",
            "6586\n",
            "6587\n",
            "6588\n",
            "6589\n",
            "6590\n",
            "6591\n",
            "6592\n",
            "6593\n",
            "6594\n",
            "6595\n",
            "6596\n",
            "6597\n",
            "6598\n",
            "6599\n",
            "6600\n",
            "6601\n",
            "6602\n",
            "6603\n",
            "6604\n",
            "6605\n",
            "6606\n",
            "6607\n",
            "6608\n",
            "6609\n",
            "6610\n",
            "6611\n",
            "6612\n",
            "6613\n",
            "6614\n",
            "6615\n",
            "6616\n",
            "6617\n",
            "6618\n",
            "6619\n",
            "6620\n",
            "6621\n",
            "6622\n",
            "6623\n",
            "6624\n",
            "6625\n",
            "6626\n",
            "6627\n",
            "6628\n",
            "6629\n",
            "6630\n",
            "6631\n",
            "6632\n",
            "6633\n",
            "6634\n",
            "6635\n",
            "6636\n",
            "6637\n",
            "6638\n",
            "6639\n",
            "6640\n",
            "6641\n",
            "6642\n",
            "6643\n",
            "6644\n",
            "6645\n",
            "6646\n",
            "6647\n",
            "6648\n",
            "6649\n",
            "6650\n",
            "6651\n",
            "6652\n",
            "6653\n",
            "6654\n",
            "6655\n",
            "6656\n",
            "6657\n",
            "6658\n",
            "6659\n",
            "6660\n",
            "6661\n",
            "6662\n",
            "6663\n",
            "6664\n",
            "6665\n",
            "6666\n",
            "6667\n",
            "6668\n",
            "6669\n",
            "6670\n",
            "6671\n",
            "6672\n",
            "6673\n",
            "6674\n",
            "6675\n",
            "6676\n",
            "6677\n",
            "6678\n",
            "6679\n",
            "6680\n",
            "6681\n",
            "6682\n",
            "6683\n",
            "6684\n",
            "6685\n",
            "6686\n",
            "6687\n",
            "6688\n",
            "6689\n",
            "6690\n",
            "6691\n",
            "6692\n",
            "6693\n",
            "6694\n",
            "6695\n",
            "6696\n",
            "6697\n",
            "6698\n",
            "6699\n",
            "6700\n",
            "6701\n",
            "6702\n",
            "6703\n",
            "6704\n",
            "6705\n",
            "6706\n",
            "6707\n",
            "6708\n",
            "6709\n",
            "6710\n",
            "6711\n",
            "6712\n",
            "6713\n",
            "6714\n",
            "6715\n",
            "6716\n",
            "6717\n",
            "6718\n",
            "6719\n",
            "6720\n",
            "6721\n",
            "6722\n",
            "6723\n",
            "6724\n",
            "6725\n",
            "6726\n",
            "6727\n",
            "6728\n",
            "6729\n",
            "6730\n",
            "6731\n",
            "6732\n",
            "6733\n",
            "6734\n",
            "6735\n",
            "6736\n",
            "6737\n",
            "6738\n",
            "6739\n",
            "6740\n",
            "6741\n",
            "6742\n",
            "6743\n",
            "6744\n",
            "6745\n",
            "6746\n",
            "6747\n",
            "6748\n",
            "6749\n",
            "6750\n",
            "6751\n",
            "6752\n",
            "6753\n",
            "6754\n",
            "6755\n",
            "6756\n",
            "6757\n",
            "6758\n",
            "6759\n",
            "6760\n",
            "6761\n",
            "6762\n",
            "6763\n",
            "6764\n",
            "6765\n",
            "6766\n",
            "6767\n",
            "6768\n",
            "6769\n",
            "6770\n",
            "6771\n",
            "6772\n",
            "6773\n",
            "6774\n",
            "6775\n",
            "6776\n",
            "6777\n",
            "6778\n",
            "6779\n",
            "6780\n",
            "6781\n",
            "6782\n",
            "6783\n",
            "6784\n",
            "6785\n",
            "6786\n",
            "6787\n",
            "6788\n",
            "6789\n",
            "6790\n",
            "6791\n",
            "6792\n",
            "6793\n",
            "6794\n",
            "6795\n",
            "6796\n",
            "6797\n",
            "6798\n",
            "6799\n",
            "6800\n",
            "6801\n",
            "6802\n",
            "6803\n",
            "6804\n",
            "6805\n",
            "6806\n",
            "6807\n",
            "6808\n",
            "6809\n",
            "6810\n",
            "6811\n",
            "6812\n",
            "6813\n",
            "6814\n",
            "6815\n",
            "6816\n",
            "6817\n",
            "6818\n",
            "6819\n",
            "6820\n",
            "6821\n",
            "6822\n",
            "6823\n",
            "6824\n",
            "6825\n",
            "6826\n",
            "6827\n",
            "6828\n",
            "6829\n",
            "6830\n",
            "6831\n",
            "6832\n",
            "6833\n",
            "6834\n",
            "6835\n",
            "6836\n",
            "6837\n",
            "6838\n",
            "6839\n",
            "6840\n",
            "6841\n",
            "6842\n",
            "6843\n",
            "6844\n",
            "6845\n",
            "6846\n",
            "6847\n",
            "6848\n",
            "6849\n",
            "6850\n",
            "6851\n",
            "6852\n",
            "6853\n",
            "6854\n",
            "6855\n",
            "6856\n",
            "6857\n",
            "6858\n",
            "6859\n",
            "6860\n",
            "6861\n",
            "6862\n",
            "6863\n",
            "6864\n",
            "6865\n",
            "6866\n",
            "6867\n",
            "6868\n",
            "6869\n",
            "6870\n",
            "6871\n",
            "6872\n",
            "6873\n",
            "6874\n",
            "6875\n",
            "6876\n",
            "6877\n",
            "6878\n",
            "6879\n",
            "6880\n",
            "6881\n",
            "6882\n",
            "6883\n",
            "6884\n",
            "6885\n",
            "6886\n",
            "6887\n",
            "6888\n",
            "6889\n",
            "6890\n",
            "6891\n",
            "6892\n",
            "6893\n",
            "6894\n",
            "6895\n",
            "6896\n",
            "6897\n",
            "6898\n",
            "6899\n",
            "6900\n",
            "6901\n",
            "6902\n",
            "6903\n",
            "6904\n",
            "6905\n",
            "6906\n",
            "6907\n",
            "6908\n",
            "6909\n",
            "6910\n",
            "6911\n",
            "6912\n",
            "6913\n",
            "6914\n",
            "6915\n",
            "6916\n",
            "6917\n",
            "6918\n",
            "6919\n",
            "6920\n",
            "6921\n",
            "6922\n",
            "6923\n",
            "6924\n",
            "6925\n",
            "6926\n",
            "6927\n",
            "6928\n",
            "6929\n",
            "6930\n",
            "6931\n",
            "6932\n",
            "6933\n",
            "6934\n",
            "6935\n",
            "6936\n",
            "6937\n",
            "6938\n",
            "6939\n",
            "6940\n",
            "6941\n",
            "6942\n",
            "6943\n",
            "6944\n",
            "6945\n",
            "6946\n",
            "6947\n",
            "6948\n",
            "6949\n",
            "6950\n",
            "6951\n",
            "6952\n",
            "6953\n",
            "6954\n",
            "6955\n",
            "6956\n",
            "6957\n",
            "6958\n",
            "6959\n",
            "6960\n",
            "6961\n",
            "6962\n",
            "6963\n",
            "6964\n",
            "6965\n",
            "6966\n",
            "6967\n",
            "6968\n",
            "6969\n",
            "6970\n",
            "6971\n",
            "6972\n",
            "6973\n",
            "6974\n",
            "6975\n",
            "6976\n",
            "6977\n",
            "6978\n",
            "6979\n",
            "6980\n",
            "6981\n",
            "6982\n",
            "6983\n",
            "6984\n",
            "6985\n",
            "6986\n",
            "6987\n",
            "6988\n",
            "6989\n",
            "6990\n",
            "6991\n",
            "6992\n",
            "6993\n",
            "6994\n",
            "6995\n",
            "6996\n",
            "6997\n",
            "6998\n",
            "6999\n",
            "7000\n",
            "7001\n",
            "7002\n",
            "7003\n",
            "7004\n",
            "7005\n",
            "7006\n",
            "7007\n",
            "7008\n",
            "7009\n",
            "7010\n",
            "7011\n",
            "7012\n",
            "7013\n",
            "7014\n",
            "7015\n",
            "7016\n",
            "7017\n",
            "7018\n",
            "7019\n",
            "7020\n",
            "7021\n",
            "7022\n",
            "7023\n",
            "7024\n",
            "7025\n",
            "7026\n",
            "7027\n",
            "7028\n",
            "7029\n",
            "7030\n",
            "7031\n",
            "7032\n",
            "7033\n",
            "7034\n",
            "7035\n",
            "7036\n",
            "7037\n",
            "7038\n",
            "7039\n",
            "7040\n",
            "7041\n",
            "7042\n",
            "7043\n",
            "7044\n",
            "7045\n",
            "7046\n",
            "7047\n",
            "7048\n",
            "7049\n",
            "7050\n",
            "7051\n",
            "7052\n",
            "7053\n",
            "7054\n",
            "7055\n",
            "7056\n",
            "7057\n",
            "7058\n",
            "7059\n",
            "7060\n",
            "7061\n",
            "7062\n",
            "7063\n",
            "7064\n",
            "7065\n",
            "7066\n",
            "7067\n",
            "7068\n",
            "7069\n",
            "7070\n",
            "7071\n",
            "7072\n",
            "7073\n",
            "7074\n",
            "7075\n",
            "7076\n",
            "7077\n",
            "7078\n",
            "7079\n",
            "7080\n",
            "7081\n",
            "7082\n",
            "7083\n",
            "7084\n",
            "7085\n",
            "7086\n",
            "7087\n",
            "7088\n",
            "7089\n",
            "7090\n",
            "7091\n",
            "7092\n",
            "7093\n",
            "7094\n",
            "7095\n",
            "7096\n",
            "7097\n",
            "7098\n",
            "7099\n",
            "7100\n",
            "7101\n",
            "7102\n",
            "7103\n",
            "7104\n",
            "7105\n",
            "7106\n",
            "7107\n",
            "7108\n",
            "7109\n",
            "7110\n",
            "7111\n",
            "7112\n",
            "7113\n",
            "7114\n",
            "7115\n",
            "7116\n",
            "7117\n",
            "7118\n",
            "7119\n",
            "7120\n",
            "7121\n",
            "7122\n",
            "7123\n",
            "7124\n",
            "7125\n",
            "7126\n",
            "7127\n",
            "7128\n",
            "7129\n",
            "7130\n",
            "7131\n",
            "7132\n",
            "7133\n",
            "7134\n",
            "7135\n",
            "7136\n",
            "7137\n",
            "7138\n",
            "7139\n",
            "7140\n",
            "7141\n",
            "7142\n",
            "7143\n",
            "7144\n",
            "7145\n",
            "7146\n",
            "7147\n",
            "7148\n",
            "7149\n",
            "7150\n",
            "7151\n",
            "7152\n",
            "7153\n",
            "7154\n",
            "7155\n",
            "7156\n",
            "7157\n",
            "7158\n",
            "7159\n",
            "7160\n",
            "7161\n",
            "7162\n",
            "7163\n",
            "7164\n",
            "7165\n",
            "7166\n",
            "7167\n",
            "7168\n",
            "7169\n",
            "7170\n",
            "7171\n",
            "7172\n",
            "7173\n",
            "7174\n",
            "7175\n",
            "7176\n",
            "7177\n",
            "7178\n",
            "7179\n",
            "7180\n",
            "7181\n",
            "7182\n",
            "7183\n",
            "7184\n",
            "7185\n",
            "7186\n",
            "7187\n",
            "7188\n",
            "7189\n",
            "7190\n",
            "7191\n",
            "7192\n",
            "7193\n",
            "7194\n",
            "7195\n",
            "7196\n",
            "7197\n",
            "7198\n",
            "7199\n",
            "7200\n",
            "7201\n",
            "7202\n",
            "7203\n",
            "7204\n",
            "7205\n",
            "7206\n",
            "7207\n",
            "7208\n",
            "7209\n",
            "7210\n",
            "7211\n",
            "7212\n",
            "7213\n",
            "7214\n",
            "7215\n",
            "7216\n",
            "7217\n",
            "7218\n",
            "7219\n",
            "7220\n",
            "7221\n",
            "7222\n",
            "7223\n",
            "7224\n",
            "7225\n",
            "7226\n",
            "7227\n",
            "7228\n",
            "7229\n",
            "7230\n",
            "7231\n",
            "7232\n",
            "7233\n",
            "7234\n",
            "7235\n",
            "7236\n",
            "7237\n",
            "7238\n",
            "7239\n",
            "7240\n",
            "7241\n",
            "7242\n",
            "7243\n",
            "7244\n",
            "7245\n",
            "7246\n",
            "7247\n",
            "7248\n",
            "7249\n",
            "7250\n",
            "7251\n",
            "7252\n",
            "7253\n",
            "7254\n",
            "7255\n",
            "7256\n",
            "7257\n",
            "7258\n",
            "7259\n",
            "7260\n",
            "7261\n",
            "7262\n",
            "7263\n",
            "7264\n",
            "7265\n",
            "7266\n",
            "7267\n",
            "7268\n",
            "7269\n",
            "7270\n",
            "7271\n",
            "7272\n",
            "7273\n",
            "7274\n",
            "7275\n",
            "7276\n",
            "7277\n",
            "7278\n",
            "7279\n",
            "7280\n",
            "7281\n",
            "7282\n",
            "7283\n",
            "7284\n",
            "7285\n",
            "7286\n",
            "7287\n",
            "7288\n",
            "7289\n",
            "7290\n",
            "7291\n",
            "7292\n",
            "7293\n",
            "7294\n",
            "7295\n",
            "7296\n",
            "7297\n",
            "7298\n",
            "7299\n",
            "7300\n",
            "7301\n",
            "7302\n",
            "7303\n",
            "7304\n",
            "7305\n",
            "7306\n",
            "7307\n",
            "7308\n",
            "7309\n",
            "7310\n",
            "7311\n",
            "7312\n",
            "7313\n",
            "7314\n",
            "7315\n",
            "7316\n",
            "7317\n",
            "7318\n",
            "7319\n",
            "7320\n",
            "7321\n",
            "7322\n",
            "7323\n",
            "7324\n",
            "7325\n",
            "7326\n",
            "7327\n",
            "7328\n",
            "7329\n",
            "7330\n",
            "7331\n",
            "7332\n",
            "7333\n",
            "7334\n",
            "7335\n",
            "7336\n",
            "7337\n",
            "7338\n",
            "7339\n",
            "7340\n",
            "7341\n",
            "7342\n",
            "7343\n",
            "7344\n",
            "7345\n",
            "7346\n",
            "7347\n",
            "7348\n",
            "7349\n",
            "7350\n",
            "7351\n",
            "7352\n",
            "7353\n",
            "7354\n",
            "7355\n",
            "7356\n",
            "7357\n",
            "7358\n",
            "7359\n",
            "7360\n",
            "7361\n",
            "7362\n",
            "7363\n",
            "7364\n",
            "7365\n",
            "7366\n",
            "7367\n",
            "7368\n",
            "7369\n",
            "7370\n",
            "7371\n",
            "7372\n",
            "7373\n",
            "7374\n",
            "7375\n",
            "7376\n",
            "7377\n",
            "7378\n",
            "7379\n",
            "7380\n",
            "7381\n",
            "7382\n",
            "7383\n",
            "7384\n",
            "7385\n",
            "7386\n",
            "7387\n",
            "7388\n",
            "7389\n",
            "7390\n",
            "7391\n",
            "7392\n",
            "7393\n",
            "7394\n",
            "7395\n",
            "7396\n",
            "7397\n",
            "7398\n",
            "7399\n",
            "7400\n",
            "7401\n",
            "7402\n",
            "7403\n",
            "7404\n",
            "7405\n",
            "7406\n",
            "7407\n",
            "7408\n",
            "7409\n",
            "7410\n",
            "7411\n",
            "7412\n",
            "7413\n",
            "7414\n",
            "7415\n",
            "7416\n",
            "7417\n",
            "7418\n",
            "7419\n",
            "7420\n",
            "7421\n",
            "7422\n",
            "7423\n",
            "7424\n",
            "7425\n",
            "7426\n",
            "7427\n",
            "7428\n",
            "7429\n",
            "7430\n",
            "7431\n",
            "7432\n",
            "7433\n",
            "7434\n",
            "7435\n",
            "7436\n",
            "7437\n",
            "7438\n",
            "7439\n",
            "7440\n",
            "7441\n",
            "7442\n",
            "7443\n",
            "7444\n",
            "7445\n",
            "7446\n",
            "7447\n",
            "7448\n",
            "7449\n",
            "7450\n",
            "7451\n",
            "7452\n",
            "7453\n",
            "7454\n",
            "7455\n",
            "7456\n",
            "7457\n",
            "7458\n",
            "7459\n",
            "7460\n",
            "7461\n",
            "7462\n",
            "7463\n",
            "7464\n",
            "7465\n",
            "7466\n",
            "7467\n",
            "7468\n",
            "7469\n",
            "7470\n",
            "7471\n",
            "7472\n",
            "7473\n",
            "7474\n",
            "7475\n",
            "7476\n",
            "7477\n",
            "7478\n",
            "7479\n",
            "7480\n",
            "7481\n",
            "7482\n",
            "7483\n",
            "7484\n",
            "7485\n",
            "7486\n",
            "7487\n",
            "7488\n",
            "7489\n",
            "7490\n",
            "7491\n",
            "7492\n",
            "7493\n",
            "7494\n",
            "7495\n",
            "7496\n",
            "7497\n",
            "7498\n",
            "7499\n",
            "7500\n",
            "7501\n",
            "7502\n",
            "7503\n",
            "7504\n",
            "7505\n",
            "7506\n",
            "7507\n",
            "7508\n",
            "7509\n",
            "7510\n",
            "7511\n",
            "7512\n",
            "7513\n",
            "7514\n",
            "7515\n",
            "7516\n",
            "7517\n",
            "7518\n",
            "7519\n",
            "7520\n",
            "7521\n",
            "7522\n",
            "7523\n",
            "7524\n",
            "7525\n",
            "7526\n",
            "7527\n",
            "7528\n",
            "7529\n",
            "7530\n",
            "7531\n",
            "7532\n",
            "7533\n",
            "7534\n",
            "7535\n",
            "7536\n",
            "7537\n",
            "7538\n",
            "7539\n",
            "7540\n",
            "7541\n",
            "7542\n",
            "7543\n",
            "7544\n",
            "7545\n",
            "7546\n",
            "7547\n",
            "7548\n",
            "7549\n",
            "7550\n",
            "7551\n",
            "7552\n",
            "7553\n",
            "7554\n",
            "7555\n",
            "7556\n",
            "7557\n",
            "7558\n",
            "7559\n",
            "7560\n",
            "7561\n",
            "7562\n",
            "7563\n",
            "7564\n",
            "7565\n",
            "7566\n",
            "7567\n",
            "7568\n",
            "7569\n",
            "7570\n",
            "7571\n",
            "7572\n",
            "7573\n",
            "7574\n",
            "7575\n",
            "7576\n",
            "7577\n",
            "7578\n",
            "7579\n",
            "7580\n",
            "7581\n",
            "7582\n",
            "7583\n",
            "7584\n",
            "7585\n",
            "7586\n",
            "7587\n",
            "7588\n",
            "7589\n",
            "7590\n",
            "7591\n",
            "7592\n",
            "7593\n",
            "7594\n",
            "7595\n",
            "7596\n",
            "7597\n",
            "7598\n",
            "7599\n",
            "7600\n",
            "7601\n",
            "7602\n",
            "7603\n",
            "7604\n",
            "7605\n",
            "7606\n",
            "7607\n",
            "7608\n",
            "7609\n",
            "7610\n",
            "7611\n",
            "7612\n",
            "7613\n",
            "7614\n",
            "7615\n",
            "7616\n",
            "7617\n",
            "7618\n",
            "7619\n",
            "7620\n",
            "7621\n",
            "7622\n",
            "7623\n",
            "7624\n",
            "7625\n",
            "7626\n",
            "7627\n",
            "7628\n",
            "7629\n",
            "7630\n",
            "7631\n",
            "7632\n",
            "7633\n",
            "7634\n",
            "7635\n",
            "7636\n",
            "7637\n",
            "7638\n",
            "7639\n",
            "7640\n",
            "7641\n",
            "7642\n",
            "7643\n",
            "7644\n",
            "7645\n",
            "7646\n",
            "7647\n",
            "7648\n",
            "7649\n",
            "7650\n",
            "7651\n",
            "7652\n",
            "7653\n",
            "7654\n",
            "7655\n",
            "7656\n",
            "7657\n",
            "7658\n",
            "7659\n",
            "7660\n",
            "7661\n",
            "7662\n",
            "7663\n",
            "7664\n",
            "7665\n",
            "7666\n",
            "7667\n",
            "7668\n",
            "7669\n",
            "7670\n",
            "7671\n",
            "7672\n",
            "7673\n",
            "7674\n",
            "7675\n",
            "7676\n",
            "7677\n",
            "7678\n",
            "7679\n",
            "7680\n",
            "7681\n",
            "7682\n",
            "7683\n",
            "7684\n",
            "7685\n",
            "7686\n",
            "7687\n",
            "7688\n",
            "7689\n",
            "7690\n",
            "7691\n",
            "7692\n",
            "7693\n",
            "7694\n",
            "7695\n",
            "7696\n",
            "7697\n",
            "7698\n",
            "7699\n",
            "7700\n",
            "7701\n",
            "7702\n",
            "7703\n",
            "7704\n",
            "7705\n",
            "7706\n",
            "7707\n",
            "7708\n",
            "7709\n",
            "7710\n",
            "7711\n",
            "7712\n",
            "7713\n",
            "7714\n",
            "7715\n",
            "7716\n",
            "7717\n",
            "7718\n",
            "7719\n",
            "7720\n",
            "7721\n",
            "7722\n",
            "7723\n",
            "7724\n",
            "7725\n",
            "7726\n",
            "7727\n",
            "7728\n",
            "7729\n",
            "7730\n",
            "7731\n",
            "7732\n",
            "7733\n",
            "7734\n",
            "7735\n",
            "7736\n",
            "7737\n",
            "7738\n",
            "7739\n",
            "7740\n",
            "7741\n",
            "7742\n",
            "7743\n",
            "7744\n",
            "7745\n",
            "7746\n",
            "7747\n",
            "7748\n",
            "7749\n",
            "7750\n",
            "7751\n",
            "7752\n",
            "7753\n",
            "7754\n",
            "7755\n",
            "7756\n",
            "7757\n",
            "7758\n",
            "7759\n",
            "7760\n",
            "7761\n",
            "7762\n",
            "7763\n",
            "7764\n",
            "7765\n",
            "7766\n",
            "7767\n",
            "7768\n",
            "7769\n",
            "7770\n",
            "7771\n",
            "7772\n",
            "7773\n",
            "7774\n",
            "7775\n",
            "7776\n",
            "7777\n",
            "7778\n",
            "7779\n",
            "7780\n",
            "7781\n",
            "7782\n",
            "7783\n",
            "7784\n",
            "7785\n",
            "7786\n",
            "7787\n",
            "7788\n",
            "7789\n",
            "7790\n",
            "7791\n",
            "7792\n",
            "7793\n",
            "7794\n",
            "7795\n",
            "7796\n",
            "7797\n",
            "7798\n",
            "7799\n",
            "7800\n",
            "7801\n",
            "7802\n",
            "7803\n",
            "7804\n",
            "7805\n",
            "7806\n",
            "7807\n",
            "7808\n",
            "7809\n",
            "7810\n",
            "7811\n",
            "7812\n",
            "7813\n",
            "7814\n",
            "7815\n",
            "7816\n",
            "7817\n",
            "7818\n",
            "7819\n",
            "7820\n",
            "7821\n",
            "7822\n",
            "7823\n",
            "7824\n",
            "7825\n",
            "7826\n",
            "7827\n",
            "7828\n",
            "7829\n",
            "7830\n",
            "7831\n",
            "7832\n",
            "7833\n",
            "7834\n",
            "7835\n",
            "7836\n",
            "7837\n",
            "7838\n",
            "7839\n",
            "7840\n",
            "7841\n",
            "7842\n",
            "7843\n",
            "7844\n",
            "7845\n",
            "7846\n",
            "7847\n",
            "7848\n",
            "7849\n",
            "7850\n",
            "7851\n",
            "7852\n",
            "7853\n",
            "7854\n",
            "7855\n",
            "7856\n",
            "7857\n",
            "7858\n",
            "7859\n",
            "7860\n",
            "7861\n",
            "7862\n",
            "7863\n",
            "7864\n",
            "7865\n",
            "7866\n",
            "7867\n",
            "7868\n",
            "7869\n",
            "7870\n",
            "7871\n",
            "7872\n",
            "7873\n",
            "7874\n",
            "7875\n",
            "7876\n",
            "7877\n",
            "7878\n",
            "7879\n",
            "7880\n",
            "7881\n",
            "7882\n",
            "7883\n",
            "7884\n",
            "7885\n",
            "7886\n",
            "7887\n",
            "7888\n",
            "7889\n",
            "7890\n",
            "7891\n",
            "7892\n",
            "7893\n",
            "7894\n",
            "7895\n",
            "7896\n",
            "7897\n",
            "7898\n",
            "7899\n",
            "7900\n",
            "7901\n",
            "7902\n",
            "7903\n",
            "7904\n",
            "7905\n",
            "7906\n",
            "7907\n",
            "7908\n",
            "7909\n",
            "7910\n",
            "7911\n",
            "7912\n",
            "7913\n",
            "7914\n",
            "7915\n",
            "7916\n",
            "7917\n",
            "7918\n",
            "7919\n",
            "7920\n",
            "7921\n",
            "7922\n",
            "7923\n",
            "7924\n",
            "7925\n",
            "7926\n",
            "7927\n",
            "7928\n",
            "7929\n",
            "7930\n",
            "7931\n",
            "7932\n",
            "7933\n",
            "7934\n",
            "7935\n",
            "7936\n",
            "7937\n",
            "7938\n",
            "7939\n",
            "7940\n",
            "7941\n",
            "7942\n",
            "7943\n",
            "7944\n",
            "7945\n",
            "7946\n",
            "7947\n",
            "7948\n",
            "7949\n",
            "7950\n",
            "7951\n",
            "7952\n",
            "7953\n",
            "7954\n",
            "7955\n",
            "7956\n",
            "7957\n",
            "7958\n",
            "7959\n",
            "7960\n",
            "7961\n",
            "7962\n",
            "7963\n",
            "7964\n",
            "7965\n",
            "7966\n",
            "7967\n",
            "7968\n",
            "7969\n",
            "7970\n",
            "7971\n",
            "7972\n",
            "7973\n",
            "7974\n",
            "7975\n",
            "7976\n",
            "7977\n",
            "7978\n",
            "7979\n",
            "7980\n",
            "7981\n",
            "7982\n",
            "7983\n",
            "7984\n",
            "7985\n",
            "7986\n",
            "7987\n",
            "7988\n",
            "7989\n",
            "7990\n",
            "7991\n",
            "7992\n",
            "7993\n",
            "7994\n",
            "7995\n",
            "7996\n",
            "7997\n",
            "7998\n",
            "7999\n",
            "8000\n",
            "8001\n",
            "8002\n",
            "8003\n",
            "8004\n",
            "8005\n",
            "8006\n",
            "8007\n",
            "8008\n",
            "8009\n",
            "8010\n",
            "8011\n",
            "8012\n",
            "8013\n",
            "8014\n",
            "8015\n",
            "8016\n",
            "8017\n",
            "8018\n",
            "8019\n",
            "8020\n",
            "8021\n",
            "8022\n",
            "8023\n",
            "8024\n",
            "8025\n",
            "8026\n",
            "8027\n",
            "8028\n",
            "8029\n",
            "8030\n",
            "8031\n",
            "8032\n",
            "8033\n",
            "8034\n",
            "8035\n",
            "8036\n",
            "8037\n",
            "8038\n",
            "8039\n",
            "8040\n",
            "8041\n",
            "8042\n",
            "8043\n",
            "8044\n",
            "8045\n",
            "8046\n",
            "8047\n",
            "8048\n",
            "8049\n",
            "8050\n",
            "8051\n",
            "8052\n",
            "8053\n",
            "8054\n",
            "8055\n",
            "8056\n",
            "8057\n",
            "8058\n",
            "8059\n",
            "8060\n",
            "8061\n",
            "8062\n",
            "8063\n",
            "8064\n",
            "8065\n",
            "8066\n",
            "8067\n",
            "8068\n",
            "8069\n",
            "8070\n",
            "8071\n",
            "8072\n",
            "8073\n",
            "8074\n",
            "8075\n",
            "8076\n",
            "8077\n",
            "8078\n",
            "8079\n",
            "8080\n",
            "8081\n",
            "8082\n",
            "8083\n",
            "8084\n",
            "8085\n",
            "8086\n",
            "8087\n",
            "8088\n",
            "8089\n",
            "8090\n",
            "8091\n",
            "8092\n",
            "8093\n",
            "8094\n",
            "8095\n",
            "8096\n",
            "8097\n",
            "8098\n",
            "8099\n",
            "8100\n",
            "8101\n",
            "8102\n",
            "8103\n",
            "8104\n",
            "8105\n",
            "8106\n",
            "8107\n",
            "8108\n",
            "8109\n",
            "8110\n",
            "8111\n",
            "8112\n",
            "8113\n",
            "8114\n",
            "8115\n",
            "8116\n",
            "8117\n",
            "8118\n",
            "8119\n",
            "8120\n",
            "8121\n",
            "8122\n",
            "8123\n",
            "8124\n",
            "8125\n",
            "8126\n",
            "8127\n",
            "8128\n",
            "8129\n",
            "8130\n",
            "8131\n",
            "8132\n",
            "8133\n",
            "8134\n",
            "8135\n",
            "8136\n",
            "8137\n",
            "8138\n",
            "8139\n",
            "8140\n",
            "8141\n",
            "8142\n",
            "8143\n",
            "8144\n",
            "8145\n",
            "8146\n",
            "8147\n",
            "8148\n",
            "8149\n",
            "8150\n",
            "8151\n",
            "8152\n",
            "8153\n",
            "8154\n",
            "8155\n",
            "8156\n",
            "8157\n",
            "8158\n",
            "8159\n",
            "8160\n",
            "8161\n",
            "8162\n",
            "8163\n",
            "8164\n",
            "8165\n",
            "8166\n",
            "8167\n",
            "8168\n",
            "8169\n",
            "8170\n",
            "8171\n",
            "8172\n",
            "8173\n",
            "8174\n",
            "8175\n",
            "8176\n",
            "8177\n",
            "8178\n",
            "8179\n",
            "8180\n",
            "8181\n",
            "8182\n",
            "8183\n",
            "8184\n",
            "8185\n",
            "8186\n",
            "8187\n",
            "8188\n",
            "8189\n",
            "8190\n",
            "8191\n",
            "8192\n",
            "8193\n",
            "8194\n",
            "8195\n",
            "8196\n",
            "8197\n",
            "8198\n",
            "8199\n",
            "8200\n",
            "8201\n",
            "8202\n",
            "8203\n",
            "8204\n",
            "8205\n",
            "8206\n",
            "8207\n",
            "8208\n",
            "8209\n",
            "8210\n",
            "8211\n",
            "8212\n",
            "8213\n",
            "8214\n",
            "8215\n",
            "8216\n",
            "8217\n",
            "8218\n",
            "8219\n",
            "8220\n",
            "8221\n",
            "8222\n",
            "8223\n",
            "8224\n",
            "8225\n",
            "8226\n",
            "8227\n",
            "8228\n",
            "8229\n",
            "8230\n",
            "8231\n",
            "8232\n",
            "8233\n",
            "8234\n",
            "8235\n",
            "8236\n",
            "8237\n",
            "8238\n",
            "8239\n",
            "8240\n",
            "8241\n",
            "8242\n",
            "8243\n",
            "8244\n",
            "8245\n",
            "8246\n",
            "8247\n",
            "8248\n",
            "8249\n",
            "8250\n",
            "8251\n",
            "8252\n",
            "8253\n",
            "8254\n",
            "8255\n",
            "8256\n",
            "8257\n",
            "8258\n",
            "8259\n",
            "8260\n",
            "8261\n",
            "8262\n",
            "8263\n",
            "8264\n",
            "8265\n",
            "8266\n",
            "8267\n",
            "8268\n",
            "8269\n",
            "8270\n",
            "8271\n",
            "8272\n",
            "8273\n",
            "8274\n",
            "8275\n",
            "8276\n",
            "8277\n",
            "8278\n",
            "8279\n",
            "8280\n",
            "8281\n",
            "8282\n",
            "8283\n",
            "8284\n",
            "8285\n",
            "8286\n",
            "8287\n",
            "8288\n",
            "8289\n",
            "8290\n",
            "8291\n",
            "8292\n",
            "8293\n",
            "8294\n",
            "8295\n",
            "8296\n",
            "8297\n",
            "8298\n",
            "8299\n",
            "8300\n",
            "8301\n",
            "8302\n",
            "8303\n",
            "8304\n",
            "8305\n",
            "8306\n",
            "8307\n",
            "8308\n",
            "8309\n",
            "8310\n",
            "8311\n",
            "8312\n",
            "8313\n",
            "8314\n",
            "8315\n",
            "8316\n",
            "8317\n",
            "8318\n",
            "8319\n",
            "8320\n",
            "8321\n",
            "8322\n",
            "8323\n",
            "8324\n",
            "8325\n",
            "8326\n",
            "8327\n",
            "8328\n",
            "8329\n",
            "8330\n",
            "8331\n",
            "8332\n",
            "8333\n",
            "8334\n",
            "8335\n",
            "8336\n",
            "8337\n",
            "8338\n",
            "8339\n",
            "8340\n",
            "8341\n",
            "8342\n",
            "8343\n",
            "8344\n",
            "8345\n",
            "8346\n",
            "8347\n",
            "8348\n",
            "8349\n",
            "8350\n",
            "8351\n",
            "8352\n",
            "8353\n",
            "8354\n",
            "8355\n",
            "8356\n",
            "8357\n",
            "8358\n",
            "8359\n",
            "8360\n",
            "8361\n",
            "8362\n",
            "8363\n",
            "8364\n",
            "8365\n",
            "8366\n",
            "8367\n",
            "8368\n",
            "8369\n",
            "8370\n",
            "8371\n",
            "8372\n",
            "8373\n",
            "8374\n",
            "8375\n",
            "8376\n",
            "8377\n",
            "8378\n",
            "8379\n",
            "8380\n",
            "8381\n",
            "8382\n",
            "8383\n",
            "8384\n",
            "8385\n",
            "8386\n",
            "8387\n",
            "8388\n",
            "8389\n",
            "8390\n",
            "8391\n",
            "8392\n",
            "8393\n",
            "8394\n",
            "8395\n",
            "8396\n",
            "8397\n",
            "8398\n",
            "8399\n",
            "8400\n",
            "8401\n",
            "8402\n",
            "8403\n",
            "8404\n",
            "8405\n",
            "8406\n",
            "8407\n",
            "8408\n",
            "8409\n",
            "8410\n",
            "8411\n",
            "8412\n",
            "8413\n",
            "8414\n",
            "8415\n",
            "8416\n",
            "8417\n",
            "8418\n",
            "8419\n",
            "8420\n",
            "8421\n",
            "8422\n",
            "8423\n",
            "8424\n",
            "8425\n",
            "8426\n",
            "8427\n",
            "8428\n",
            "8429\n",
            "8430\n",
            "8431\n",
            "8432\n",
            "8433\n",
            "8434\n",
            "8435\n",
            "8436\n",
            "8437\n",
            "8438\n",
            "8439\n",
            "8440\n",
            "8441\n",
            "8442\n",
            "8443\n",
            "8444\n",
            "8445\n",
            "8446\n",
            "8447\n",
            "8448\n",
            "8449\n",
            "8450\n",
            "8451\n",
            "8452\n",
            "8453\n",
            "8454\n",
            "8455\n",
            "8456\n",
            "8457\n",
            "8458\n",
            "8459\n",
            "8460\n",
            "8461\n",
            "8462\n",
            "8463\n",
            "8464\n",
            "8465\n",
            "8466\n",
            "8467\n",
            "8468\n",
            "8469\n",
            "8470\n",
            "8471\n",
            "8472\n",
            "8473\n",
            "8474\n",
            "8475\n",
            "8476\n",
            "8477\n",
            "8478\n",
            "8479\n",
            "8480\n",
            "8481\n",
            "8482\n",
            "8483\n",
            "8484\n",
            "8485\n",
            "8486\n",
            "8487\n",
            "8488\n",
            "8489\n",
            "8490\n",
            "8491\n",
            "8492\n",
            "8493\n",
            "8494\n",
            "8495\n",
            "8496\n",
            "8497\n",
            "8498\n",
            "8499\n",
            "8500\n",
            "8501\n",
            "8502\n",
            "8503\n",
            "8504\n",
            "8505\n",
            "8506\n",
            "8507\n",
            "8508\n",
            "8509\n",
            "8510\n",
            "8511\n",
            "8512\n",
            "8513\n",
            "8514\n",
            "8515\n",
            "8516\n",
            "8517\n",
            "8518\n",
            "8519\n",
            "8520\n",
            "8521\n",
            "8522\n",
            "8523\n",
            "8524\n",
            "8525\n",
            "8526\n",
            "8527\n",
            "8528\n",
            "8529\n",
            "8530\n",
            "8531\n",
            "8532\n",
            "8533\n",
            "8534\n",
            "8535\n",
            "8536\n",
            "8537\n",
            "8538\n",
            "8539\n",
            "8540\n",
            "8541\n",
            "8542\n",
            "8543\n",
            "8544\n",
            "8545\n",
            "8546\n",
            "8547\n",
            "8548\n",
            "8549\n",
            "8550\n",
            "8551\n",
            "8552\n",
            "8553\n",
            "8554\n",
            "8555\n",
            "8556\n",
            "8557\n",
            "8558\n",
            "8559\n",
            "8560\n",
            "8561\n",
            "8562\n",
            "8563\n",
            "8564\n",
            "8565\n",
            "8566\n",
            "8567\n",
            "8568\n",
            "8569\n",
            "8570\n",
            "8571\n",
            "8572\n",
            "8573\n",
            "8574\n",
            "8575\n",
            "8576\n",
            "8577\n",
            "8578\n",
            "8579\n",
            "8580\n",
            "8581\n",
            "8582\n",
            "8583\n",
            "8584\n",
            "8585\n",
            "8586\n",
            "8587\n",
            "8588\n",
            "8589\n",
            "8590\n",
            "8591\n",
            "8592\n",
            "8593\n",
            "8594\n",
            "8595\n",
            "8596\n",
            "8597\n",
            "8598\n",
            "8599\n",
            "8600\n",
            "8601\n",
            "8602\n",
            "8603\n",
            "8604\n",
            "8605\n",
            "8606\n",
            "8607\n",
            "8608\n",
            "8609\n",
            "8610\n",
            "8611\n",
            "8612\n",
            "8613\n",
            "8614\n",
            "8615\n",
            "8616\n",
            "8617\n",
            "8618\n",
            "8619\n",
            "8620\n",
            "8621\n",
            "8622\n",
            "8623\n",
            "8624\n",
            "8625\n",
            "8626\n",
            "8627\n",
            "8628\n",
            "8629\n",
            "8630\n",
            "8631\n",
            "8632\n",
            "8633\n",
            "8634\n",
            "8635\n",
            "8636\n",
            "8637\n",
            "8638\n",
            "8639\n",
            "8640\n",
            "8641\n",
            "8642\n",
            "8643\n",
            "8644\n",
            "8645\n",
            "8646\n",
            "8647\n",
            "8648\n",
            "8649\n",
            "8650\n",
            "8651\n",
            "8652\n",
            "8653\n",
            "8654\n",
            "8655\n",
            "8656\n",
            "8657\n",
            "8658\n",
            "8659\n",
            "8660\n",
            "8661\n",
            "8662\n",
            "8663\n",
            "8664\n",
            "8665\n",
            "8666\n",
            "8667\n",
            "8668\n",
            "8669\n",
            "8670\n",
            "8671\n",
            "8672\n",
            "8673\n",
            "8674\n",
            "8675\n",
            "8676\n",
            "8677\n",
            "8678\n",
            "8679\n",
            "8680\n",
            "8681\n",
            "8682\n",
            "8683\n",
            "8684\n",
            "8685\n",
            "8686\n",
            "8687\n",
            "8688\n",
            "8689\n",
            "8690\n",
            "8691\n",
            "8692\n",
            "8693\n",
            "8694\n",
            "8695\n",
            "8696\n",
            "8697\n",
            "8698\n",
            "8699\n",
            "8700\n",
            "8701\n",
            "8702\n",
            "8703\n",
            "8704\n",
            "8705\n",
            "8706\n",
            "8707\n",
            "8708\n",
            "8709\n",
            "8710\n",
            "8711\n",
            "8712\n",
            "8713\n",
            "8714\n",
            "8715\n",
            "8716\n",
            "8717\n",
            "8718\n",
            "8719\n",
            "8720\n",
            "8721\n",
            "8722\n",
            "8723\n",
            "8724\n",
            "8725\n",
            "8726\n",
            "8727\n",
            "8728\n",
            "8729\n",
            "8730\n",
            "8731\n",
            "8732\n",
            "8733\n",
            "8734\n",
            "8735\n",
            "8736\n",
            "8737\n",
            "8738\n",
            "8739\n",
            "8740\n",
            "8741\n",
            "8742\n",
            "8743\n",
            "8744\n",
            "8745\n",
            "8746\n",
            "8747\n",
            "8748\n",
            "8749\n",
            "8750\n",
            "8751\n",
            "8752\n",
            "8753\n",
            "8754\n",
            "8755\n",
            "8756\n",
            "8757\n",
            "8758\n",
            "8759\n",
            "8760\n",
            "8761\n",
            "8762\n",
            "8763\n",
            "8764\n",
            "8765\n",
            "8766\n",
            "8767\n",
            "8768\n",
            "8769\n",
            "8770\n",
            "8771\n",
            "8772\n",
            "8773\n",
            "8774\n",
            "8775\n",
            "8776\n",
            "8777\n",
            "8778\n",
            "8779\n",
            "8780\n",
            "8781\n",
            "8782\n",
            "8783\n",
            "8784\n",
            "8785\n",
            "8786\n",
            "8787\n",
            "8788\n",
            "8789\n",
            "8790\n",
            "8791\n",
            "8792\n",
            "8793\n",
            "8794\n",
            "8795\n",
            "8796\n",
            "8797\n",
            "8798\n",
            "8799\n",
            "8800\n",
            "8801\n",
            "8802\n",
            "8803\n",
            "8804\n",
            "8805\n",
            "8806\n",
            "8807\n",
            "8808\n",
            "8809\n",
            "8810\n",
            "8811\n",
            "8812\n",
            "8813\n",
            "8814\n",
            "8815\n",
            "8816\n",
            "8817\n",
            "8818\n",
            "8819\n",
            "8820\n",
            "8821\n",
            "8822\n",
            "8823\n",
            "8824\n",
            "8825\n",
            "8826\n",
            "8827\n",
            "8828\n",
            "8829\n",
            "8830\n",
            "8831\n",
            "8832\n",
            "8833\n",
            "8834\n",
            "8835\n",
            "8836\n",
            "8837\n",
            "8838\n",
            "8839\n",
            "8840\n",
            "8841\n",
            "8842\n",
            "8843\n",
            "8844\n",
            "8845\n",
            "8846\n",
            "8847\n",
            "8848\n",
            "8849\n",
            "8850\n",
            "8851\n",
            "8852\n",
            "8853\n",
            "8854\n",
            "8855\n",
            "8856\n",
            "8857\n",
            "8858\n",
            "8859\n",
            "8860\n",
            "8861\n",
            "8862\n",
            "8863\n",
            "8864\n",
            "8865\n",
            "8866\n",
            "8867\n",
            "8868\n",
            "8869\n",
            "8870\n",
            "8871\n",
            "8872\n",
            "8873\n",
            "8874\n",
            "8875\n",
            "8876\n",
            "8877\n",
            "8878\n",
            "8879\n",
            "8880\n",
            "8881\n",
            "8882\n",
            "8883\n",
            "8884\n",
            "8885\n",
            "8886\n",
            "8887\n",
            "8888\n",
            "8889\n",
            "8890\n",
            "8891\n",
            "8892\n",
            "8893\n",
            "8894\n",
            "8895\n",
            "8896\n",
            "8897\n",
            "8898\n",
            "8899\n",
            "8900\n",
            "8901\n",
            "8902\n",
            "8903\n",
            "8904\n",
            "8905\n",
            "8906\n",
            "8907\n",
            "8908\n",
            "8909\n",
            "8910\n",
            "8911\n",
            "8912\n",
            "8913\n",
            "8914\n",
            "8915\n",
            "8916\n",
            "8917\n",
            "8918\n",
            "8919\n",
            "8920\n",
            "8921\n",
            "8922\n",
            "8923\n",
            "8924\n",
            "8925\n",
            "8926\n",
            "8927\n",
            "8928\n",
            "8929\n",
            "8930\n",
            "8931\n",
            "8932\n",
            "8933\n",
            "8934\n",
            "8935\n",
            "8936\n",
            "8937\n",
            "8938\n",
            "8939\n",
            "8940\n",
            "8941\n",
            "8942\n",
            "8943\n",
            "8944\n",
            "8945\n",
            "8946\n",
            "8947\n",
            "8948\n",
            "8949\n",
            "8950\n",
            "8951\n",
            "8952\n",
            "8953\n",
            "8954\n",
            "8955\n",
            "8956\n",
            "8957\n",
            "8958\n",
            "8959\n",
            "8960\n",
            "8961\n",
            "8962\n",
            "8963\n",
            "8964\n",
            "8965\n",
            "8966\n",
            "8967\n",
            "8968\n",
            "8969\n",
            "8970\n",
            "8971\n",
            "8972\n",
            "8973\n",
            "8974\n",
            "8975\n",
            "8976\n",
            "8977\n",
            "8978\n",
            "8979\n",
            "8980\n",
            "8981\n",
            "8982\n",
            "8983\n",
            "8984\n",
            "8985\n",
            "8986\n",
            "8987\n",
            "8988\n",
            "8989\n",
            "8990\n",
            "8991\n",
            "8992\n",
            "8993\n",
            "8994\n",
            "8995\n",
            "8996\n",
            "8997\n",
            "8998\n",
            "8999\n",
            "9000\n",
            "9001\n",
            "9002\n",
            "9003\n",
            "9004\n",
            "9005\n",
            "9006\n",
            "9007\n",
            "9008\n",
            "9009\n",
            "9010\n",
            "9011\n",
            "9012\n",
            "9013\n",
            "9014\n",
            "9015\n",
            "9016\n",
            "9017\n",
            "9018\n",
            "9019\n",
            "9020\n",
            "9021\n",
            "9022\n",
            "9023\n",
            "9024\n",
            "9025\n",
            "9026\n",
            "9027\n",
            "9028\n",
            "9029\n",
            "9030\n",
            "9031\n",
            "9032\n",
            "9033\n",
            "9034\n",
            "9035\n",
            "9036\n",
            "9037\n",
            "9038\n",
            "9039\n",
            "9040\n",
            "9041\n",
            "9042\n",
            "9043\n",
            "9044\n",
            "9045\n",
            "9046\n",
            "9047\n",
            "9048\n",
            "9049\n",
            "9050\n",
            "9051\n",
            "9052\n",
            "9053\n",
            "9054\n",
            "9055\n",
            "9056\n",
            "9057\n",
            "9058\n",
            "9059\n",
            "9060\n",
            "9061\n",
            "9062\n",
            "9063\n",
            "9064\n",
            "9065\n",
            "9066\n",
            "9067\n",
            "9068\n",
            "9069\n",
            "9070\n",
            "9071\n",
            "9072\n",
            "9073\n",
            "9074\n",
            "9075\n",
            "9076\n",
            "9077\n",
            "9078\n",
            "9079\n",
            "9080\n",
            "9081\n",
            "9082\n",
            "9083\n",
            "9084\n",
            "9085\n",
            "9086\n",
            "9087\n",
            "9088\n",
            "9089\n",
            "9090\n",
            "9091\n",
            "9092\n",
            "9093\n",
            "9094\n",
            "9095\n",
            "9096\n",
            "9097\n",
            "9098\n",
            "9099\n",
            "9100\n",
            "9101\n",
            "9102\n",
            "9103\n",
            "9104\n",
            "9105\n",
            "9106\n",
            "9107\n",
            "9108\n",
            "9109\n",
            "9110\n",
            "9111\n",
            "9112\n",
            "9113\n",
            "9114\n",
            "9115\n",
            "9116\n",
            "9117\n",
            "9118\n",
            "9119\n",
            "9120\n",
            "9121\n",
            "9122\n",
            "9123\n",
            "9124\n",
            "9125\n",
            "9126\n",
            "9127\n",
            "9128\n",
            "9129\n",
            "9130\n",
            "9131\n",
            "9132\n",
            "9133\n",
            "9134\n",
            "9135\n",
            "9136\n",
            "9137\n",
            "9138\n",
            "9139\n",
            "9140\n",
            "9141\n",
            "9142\n",
            "9143\n",
            "9144\n",
            "9145\n",
            "9146\n",
            "9147\n",
            "9148\n",
            "9149\n",
            "9150\n",
            "9151\n",
            "9152\n",
            "9153\n",
            "9154\n",
            "9155\n",
            "9156\n",
            "9157\n",
            "9158\n",
            "9159\n",
            "9160\n",
            "9161\n",
            "9162\n",
            "9163\n",
            "9164\n",
            "9165\n",
            "9166\n",
            "9167\n",
            "9168\n",
            "9169\n",
            "9170\n",
            "9171\n",
            "9172\n",
            "9173\n",
            "9174\n",
            "9175\n",
            "9176\n",
            "9177\n",
            "9178\n",
            "9179\n",
            "9180\n",
            "9181\n",
            "9182\n",
            "9183\n",
            "9184\n",
            "9185\n",
            "9186\n",
            "9187\n",
            "9188\n",
            "9189\n",
            "9190\n",
            "9191\n",
            "9192\n",
            "9193\n",
            "9194\n",
            "9195\n",
            "9196\n",
            "9197\n",
            "9198\n",
            "9199\n",
            "9200\n",
            "9201\n",
            "9202\n",
            "9203\n",
            "9204\n",
            "9205\n",
            "9206\n",
            "9207\n",
            "9208\n",
            "9209\n",
            "9210\n",
            "9211\n",
            "9212\n",
            "9213\n",
            "9214\n",
            "9215\n",
            "9216\n",
            "9217\n",
            "9218\n",
            "9219\n",
            "9220\n",
            "9221\n",
            "9222\n",
            "9223\n",
            "9224\n",
            "9225\n",
            "9226\n",
            "9227\n",
            "9228\n",
            "9229\n",
            "9230\n",
            "9231\n",
            "9232\n",
            "9233\n",
            "9234\n",
            "9235\n",
            "9236\n",
            "9237\n",
            "9238\n",
            "9239\n",
            "9240\n",
            "9241\n",
            "9242\n",
            "9243\n",
            "9244\n",
            "9245\n",
            "9246\n",
            "9247\n",
            "9248\n",
            "9249\n",
            "9250\n",
            "9251\n",
            "9252\n",
            "9253\n",
            "9254\n",
            "9255\n",
            "9256\n",
            "9257\n",
            "9258\n",
            "9259\n",
            "9260\n",
            "9261\n",
            "9262\n",
            "9263\n",
            "9264\n",
            "9265\n",
            "9266\n",
            "9267\n",
            "9268\n",
            "9269\n",
            "9270\n",
            "9271\n",
            "9272\n",
            "9273\n",
            "9274\n",
            "9275\n",
            "9276\n",
            "9277\n",
            "9278\n",
            "9279\n",
            "9280\n",
            "9281\n",
            "9282\n",
            "9283\n",
            "9284\n",
            "9285\n",
            "9286\n",
            "9287\n",
            "9288\n",
            "9289\n",
            "9290\n",
            "9291\n",
            "9292\n",
            "9293\n",
            "9294\n",
            "9295\n",
            "9296\n",
            "9297\n",
            "9298\n",
            "9299\n",
            "9300\n",
            "9301\n",
            "9302\n",
            "9303\n",
            "9304\n",
            "9305\n",
            "9306\n",
            "9307\n",
            "9308\n",
            "9309\n",
            "9310\n",
            "9311\n",
            "9312\n",
            "9313\n",
            "9314\n",
            "9315\n",
            "9316\n",
            "9317\n",
            "9318\n",
            "9319\n",
            "9320\n",
            "9321\n",
            "9322\n",
            "9323\n",
            "9324\n",
            "9325\n",
            "9326\n",
            "9327\n",
            "9328\n",
            "9329\n",
            "9330\n",
            "9331\n",
            "9332\n",
            "9333\n",
            "9334\n",
            "9335\n",
            "9336\n",
            "9337\n",
            "9338\n",
            "9339\n",
            "9340\n",
            "9341\n",
            "9342\n",
            "9343\n",
            "9344\n",
            "9345\n",
            "9346\n",
            "9347\n",
            "9348\n",
            "9349\n",
            "9350\n",
            "9351\n",
            "9352\n",
            "9353\n",
            "9354\n",
            "9355\n",
            "9356\n",
            "9357\n",
            "9358\n",
            "9359\n",
            "9360\n",
            "9361\n",
            "9362\n",
            "9363\n",
            "9364\n",
            "9365\n",
            "9366\n",
            "9367\n",
            "9368\n",
            "9369\n",
            "9370\n",
            "9371\n",
            "9372\n",
            "9373\n",
            "9374\n",
            "9375\n",
            "9376\n",
            "9377\n",
            "9378\n",
            "9379\n",
            "9380\n",
            "9381\n",
            "9382\n",
            "9383\n",
            "9384\n",
            "9385\n",
            "9386\n",
            "9387\n",
            "9388\n",
            "9389\n",
            "9390\n",
            "9391\n",
            "9392\n",
            "9393\n",
            "9394\n",
            "9395\n",
            "9396\n",
            "9397\n",
            "9398\n",
            "9399\n",
            "9400\n",
            "9401\n",
            "9402\n",
            "9403\n",
            "9404\n",
            "9405\n",
            "9406\n",
            "9407\n",
            "9408\n",
            "9409\n",
            "9410\n",
            "9411\n",
            "9412\n",
            "9413\n",
            "9414\n",
            "9415\n",
            "9416\n",
            "9417\n",
            "9418\n",
            "9419\n",
            "9420\n",
            "9421\n",
            "9422\n",
            "9423\n",
            "9424\n",
            "9425\n",
            "9426\n",
            "9427\n",
            "9428\n",
            "9429\n",
            "9430\n",
            "9431\n",
            "9432\n",
            "9433\n",
            "9434\n",
            "9435\n",
            "9436\n",
            "9437\n",
            "9438\n",
            "9439\n",
            "9440\n",
            "9441\n",
            "9442\n",
            "9443\n",
            "9444\n",
            "9445\n",
            "9446\n",
            "9447\n",
            "9448\n",
            "9449\n",
            "9450\n",
            "9451\n",
            "9452\n",
            "9453\n",
            "9454\n",
            "9455\n",
            "9456\n",
            "9457\n",
            "9458\n",
            "9459\n",
            "9460\n",
            "9461\n",
            "9462\n",
            "9463\n",
            "9464\n",
            "9465\n",
            "9466\n",
            "9467\n",
            "9468\n",
            "9469\n",
            "9470\n",
            "9471\n",
            "9472\n",
            "9473\n",
            "9474\n",
            "9475\n",
            "9476\n",
            "9477\n",
            "9478\n",
            "9479\n",
            "9480\n",
            "9481\n",
            "9482\n",
            "9483\n",
            "9484\n",
            "9485\n",
            "9486\n",
            "9487\n",
            "9488\n",
            "9489\n",
            "9490\n",
            "9491\n",
            "9492\n",
            "9493\n",
            "9494\n",
            "9495\n",
            "9496\n",
            "9497\n",
            "9498\n",
            "9499\n",
            "9500\n",
            "9501\n",
            "9502\n",
            "9503\n",
            "9504\n",
            "9505\n",
            "9506\n",
            "9507\n",
            "9508\n",
            "9509\n",
            "9510\n",
            "9511\n",
            "9512\n",
            "9513\n",
            "9514\n",
            "9515\n",
            "9516\n",
            "9517\n",
            "9518\n",
            "9519\n",
            "9520\n",
            "9521\n",
            "9522\n",
            "9523\n",
            "9524\n",
            "9525\n",
            "9526\n",
            "9527\n",
            "9528\n",
            "9529\n",
            "9530\n",
            "9531\n",
            "9532\n",
            "9533\n",
            "9534\n",
            "9535\n",
            "9536\n",
            "9537\n",
            "9538\n",
            "9539\n",
            "9540\n",
            "9541\n",
            "9542\n",
            "9543\n",
            "9544\n",
            "9545\n",
            "9546\n",
            "9547\n",
            "9548\n",
            "9549\n",
            "9550\n",
            "9551\n",
            "9552\n",
            "9553\n",
            "9554\n",
            "9555\n",
            "9556\n",
            "9557\n",
            "9558\n",
            "9559\n",
            "9560\n",
            "9561\n",
            "9562\n",
            "9563\n",
            "9564\n",
            "9565\n",
            "9566\n",
            "9567\n",
            "9568\n",
            "9569\n",
            "9570\n",
            "9571\n",
            "9572\n",
            "9573\n",
            "9574\n",
            "9575\n",
            "9576\n",
            "9577\n",
            "9578\n",
            "9579\n",
            "9580\n",
            "9581\n",
            "9582\n",
            "9583\n",
            "9584\n",
            "9585\n",
            "9586\n",
            "9587\n",
            "9588\n",
            "9589\n",
            "9590\n",
            "9591\n",
            "9592\n",
            "9593\n",
            "9594\n",
            "9595\n",
            "9596\n",
            "9597\n",
            "9598\n",
            "9599\n",
            "9600\n",
            "9601\n",
            "9602\n",
            "9603\n",
            "9604\n",
            "9605\n",
            "9606\n",
            "9607\n",
            "9608\n",
            "9609\n",
            "9610\n",
            "9611\n",
            "9612\n",
            "9613\n",
            "9614\n",
            "9615\n",
            "9616\n",
            "9617\n",
            "9618\n",
            "9619\n",
            "9620\n",
            "9621\n",
            "9622\n",
            "9623\n",
            "9624\n",
            "9625\n",
            "9626\n",
            "9627\n",
            "9628\n",
            "9629\n",
            "9630\n",
            "9631\n",
            "9632\n",
            "9633\n",
            "9634\n",
            "9635\n",
            "9636\n",
            "9637\n",
            "9638\n",
            "9639\n",
            "9640\n",
            "9641\n",
            "9642\n",
            "9643\n",
            "9644\n",
            "9645\n",
            "9646\n",
            "9647\n",
            "9648\n",
            "9649\n",
            "9650\n",
            "9651\n",
            "9652\n",
            "9653\n",
            "9654\n",
            "9655\n",
            "9656\n",
            "9657\n",
            "9658\n",
            "9659\n",
            "9660\n",
            "9661\n",
            "9662\n",
            "9663\n",
            "9664\n",
            "9665\n",
            "9666\n",
            "9667\n",
            "9668\n",
            "9669\n",
            "9670\n",
            "9671\n",
            "9672\n",
            "9673\n",
            "9674\n",
            "9675\n",
            "9676\n",
            "9677\n",
            "9678\n",
            "9679\n",
            "9680\n",
            "9681\n",
            "9682\n",
            "9683\n",
            "9684\n",
            "9685\n",
            "9686\n",
            "9687\n",
            "9688\n",
            "9689\n",
            "9690\n",
            "9691\n",
            "9692\n",
            "9693\n",
            "9694\n",
            "9695\n",
            "9696\n",
            "9697\n",
            "9698\n",
            "9699\n",
            "9700\n",
            "9701\n",
            "9702\n",
            "9703\n",
            "9704\n",
            "9705\n",
            "9706\n",
            "9707\n",
            "9708\n",
            "9709\n",
            "9710\n",
            "9711\n",
            "9712\n",
            "9713\n",
            "9714\n",
            "9715\n",
            "9716\n",
            "9717\n",
            "9718\n",
            "9719\n",
            "9720\n",
            "9721\n",
            "9722\n",
            "9723\n",
            "9724\n",
            "9725\n",
            "9726\n",
            "9727\n",
            "9728\n",
            "9729\n",
            "9730\n",
            "9731\n",
            "9732\n",
            "9733\n",
            "9734\n",
            "9735\n",
            "9736\n",
            "9737\n",
            "9738\n",
            "9739\n",
            "9740\n",
            "9741\n",
            "9742\n",
            "9743\n",
            "9744\n",
            "9745\n",
            "9746\n",
            "9747\n",
            "9748\n",
            "9749\n",
            "9750\n",
            "9751\n",
            "9752\n",
            "9753\n",
            "9754\n",
            "9755\n",
            "9756\n",
            "9757\n",
            "9758\n",
            "9759\n",
            "9760\n",
            "9761\n",
            "9762\n",
            "9763\n",
            "9764\n",
            "9765\n",
            "9766\n",
            "9767\n",
            "9768\n",
            "9769\n",
            "9770\n",
            "9771\n",
            "9772\n",
            "9773\n",
            "9774\n",
            "9775\n",
            "9776\n",
            "9777\n",
            "9778\n",
            "9779\n",
            "9780\n",
            "9781\n",
            "9782\n",
            "9783\n",
            "9784\n",
            "9785\n",
            "9786\n",
            "9787\n",
            "9788\n",
            "9789\n",
            "9790\n",
            "9791\n",
            "9792\n",
            "9793\n",
            "9794\n",
            "9795\n",
            "9796\n",
            "9797\n",
            "9798\n",
            "9799\n",
            "9800\n",
            "9801\n",
            "9802\n",
            "9803\n",
            "9804\n",
            "9805\n",
            "9806\n",
            "9807\n",
            "9808\n",
            "9809\n",
            "9810\n",
            "9811\n",
            "9812\n",
            "9813\n",
            "9814\n",
            "9815\n",
            "9816\n",
            "9817\n",
            "9818\n",
            "9819\n",
            "9820\n",
            "9821\n",
            "9822\n",
            "9823\n",
            "9824\n",
            "9825\n",
            "9826\n",
            "9827\n",
            "9828\n",
            "9829\n",
            "9830\n",
            "9831\n",
            "9832\n",
            "9833\n",
            "9834\n",
            "9835\n",
            "9836\n",
            "9837\n",
            "9838\n",
            "9839\n",
            "9840\n",
            "9841\n",
            "9842\n",
            "9843\n",
            "9844\n",
            "9845\n",
            "9846\n",
            "9847\n",
            "9848\n",
            "9849\n",
            "9850\n",
            "9851\n",
            "9852\n",
            "9853\n",
            "9854\n",
            "9855\n",
            "9856\n",
            "9857\n",
            "9858\n",
            "9859\n",
            "9860\n",
            "9861\n",
            "9862\n",
            "9863\n",
            "9864\n",
            "9865\n",
            "9866\n",
            "9867\n",
            "9868\n",
            "9869\n",
            "9870\n",
            "9871\n",
            "9872\n",
            "9873\n",
            "9874\n",
            "9875\n",
            "9876\n",
            "9877\n",
            "9878\n",
            "9879\n",
            "9880\n",
            "9881\n",
            "9882\n",
            "9883\n",
            "9884\n",
            "9885\n",
            "9886\n",
            "9887\n",
            "9888\n",
            "9889\n",
            "9890\n",
            "9891\n",
            "9892\n",
            "9893\n",
            "9894\n",
            "9895\n",
            "9896\n",
            "9897\n",
            "9898\n",
            "9899\n",
            "9900\n",
            "9901\n",
            "9902\n",
            "9903\n",
            "9904\n",
            "9905\n",
            "9906\n",
            "9907\n",
            "9908\n",
            "9909\n",
            "9910\n",
            "9911\n",
            "9912\n",
            "9913\n",
            "9914\n",
            "9915\n",
            "9916\n",
            "9917\n",
            "9918\n",
            "9919\n",
            "9920\n",
            "9921\n",
            "9922\n",
            "9923\n",
            "9924\n",
            "9925\n",
            "9926\n",
            "9927\n",
            "9928\n",
            "9929\n",
            "9930\n",
            "9931\n",
            "9932\n",
            "9933\n",
            "9934\n",
            "9935\n",
            "9936\n",
            "9937\n",
            "9938\n",
            "9939\n",
            "9940\n",
            "9941\n",
            "9942\n",
            "9943\n",
            "9944\n",
            "9945\n",
            "9946\n",
            "9947\n",
            "9948\n",
            "9949\n",
            "9950\n",
            "9951\n",
            "9952\n",
            "9953\n",
            "9954\n",
            "9955\n",
            "9956\n",
            "9957\n",
            "9958\n",
            "9959\n",
            "9960\n",
            "9961\n",
            "9962\n",
            "9963\n",
            "9964\n",
            "9965\n",
            "9966\n",
            "9967\n",
            "9968\n",
            "9969\n",
            "9970\n",
            "9971\n",
            "9972\n",
            "9973\n",
            "9974\n",
            "9975\n",
            "9976\n",
            "9977\n",
            "9978\n",
            "9979\n",
            "9980\n",
            "9981\n",
            "9982\n",
            "9983\n",
            "9984\n",
            "9985\n",
            "9986\n",
            "9987\n",
            "9988\n",
            "9989\n",
            "9990\n",
            "9991\n",
            "9992\n",
            "9993\n",
            "9994\n",
            "9995\n",
            "9996\n",
            "9997\n",
            "9998\n",
            "9999\n",
            "10000\n",
            "31157\n",
            "Sample function name: ag get type\n",
            "Sample sequence:  LEA RDI 0x11d920 CALL FUN MOV EDI 0x50 MOV RAX qword ptr 0x0011d920 ADD RSP 0x8 LEA RDX 0x11ccc0 CALL FUN RET XOR ECX ECX MOV RSI RAX LEA RSI AgsTimestamp\n",
            "Train size: 28119\n",
            "Dev size: 1480\n",
            "Test size: 1558\n",
            "29599\n",
            "29599\n",
            "1558\n",
            "1558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E1r7eexkDdt",
        "outputId": "a66851b1-f72c-4c7d-912a-b98f4ebdf126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# now we build a tfds tokenizer for both names and sequences\n",
        "tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    names + sequences, target_vocab_size=2**13)\n",
        "\n",
        "# Define start and end token to indicate the start and end of a sentence\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "# Vocabulary size plus start and end token\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
        "\n",
        "print('Tokenized sample name: {}'.format(tokenizer.encode(names[120])))\n",
        "print('Tokenized sample sequence: {}'.format(tokenizer.encode(sequences[120])))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized sample name: [2037]\n",
            "Tokenized sample sequence: [7877, 34, 317, 421, 2453, 47, 629]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AodqD8zkGgk",
        "outputId": "7cb679fe-88f0-4b95-e596-a50318c8b61c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Maximum sequence length \n",
        "MAX_LENGTH = 100\n",
        "\n",
        "# Tokenize, filter and pad sentences\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "  \n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # tokenize sentence\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "    # check tokenized sentence max length\n",
        "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
        "      tokenized_inputs.append(sentence1)\n",
        "      tokenized_outputs.append(sentence2)\n",
        "  \n",
        "  # pad tokenized sentences\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  \n",
        "  return tokenized_inputs, tokenized_outputs\n",
        "\n",
        "\n",
        "names, sequences = tokenize_and_filter(names, sequences)\n",
        "\n",
        "print('Vocab size: {}'.format(VOCAB_SIZE))\n",
        "print('Number of samples: {}'.format(len(sequences)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 8103\n",
            "Number of samples: 28688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bujV4iggkKXn"
      },
      "source": [
        "# 64*570 = 36000 ca.\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 570\n",
        "\n",
        "# decoder inputs use the previous target as input\n",
        "# remove START_TOKEN from targets\n",
        "\n",
        "#dataset = tf.data.Dataset.from_tensor_slices((\n",
        "#    {\n",
        "#        'inputs': sequences,\n",
        "#        'dec_inputs': names[:, :-1]\n",
        "#    },\n",
        "#    {\n",
        "#        'outputs': names[:, 1:]\n",
        "#    },\n",
        "#))\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((sequences, names))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kibR2ngCkMMV",
        "outputId": "0b59f170-8b23-4757-9172-a06f5e5c50f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(dataset)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PrefetchDataset shapes: ((None, 100), (None, 100)), types: (tf.int32, tf.int32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBqY02KDgw-d"
      },
      "source": [
        "# please note that the following implementation of functions and classes for the Transformer\n",
        "# comes (almost entirely, except for the encodings retrieval) from the following\n",
        "# tutorial: https://www.tensorflow.org/tutorials/text/transformer - the \n",
        "# architecture is not the focus at this point so I figured it would be better\n",
        "# to directly implement this to save some time and try different things and setups"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tocqiaKnkMsS",
        "outputId": "d3603958-6862-49c6-a68d-9a4fa5c60008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "# POSITIONAL ENCODING FUNCTIONS DEFINITION\n",
        "\n",
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  \n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "  \n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    \n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    \n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "pos_encoding = positional_encoding(50, 512)\n",
        "print (pos_encoding.shape)\n",
        "\n",
        "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, 512))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 50, 512)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZPX7palkm2p",
        "outputId": "a624cbf9-76bd-4ee2-955b-6a6fa7a175e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "# PADDING/LOOKAHEAD MASKING FUNCTIONS DEFINITIONS\n",
        "\n",
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  \n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
        "\n",
        "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
        "create_padding_mask(x)\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)\n",
        "\n",
        "x = tf.random.uniform((1, 3))\n",
        "temp = create_look_ahead_mask(x.shape[1])\n",
        "temp"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[0., 1., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20Im-5XBkywM",
        "outputId": "1458f450-d7b2-4f70-f546-4662d8b829d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "# SCALED DOT PRODUCT ATTENTION DEFINITION\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead) \n",
        "  but it must be broadcastable for addition.\n",
        "  \n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable \n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "    \n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights\n",
        "\n",
        "def print_out(q, k, v):\n",
        "  temp_out, temp_attn = scaled_dot_product_attention(\n",
        "      q, k, v, None)\n",
        "  print ('Attention weights are:')\n",
        "  print (temp_attn)\n",
        "  print ('Output is:')\n",
        "  print (temp_out)\n",
        "\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "temp_k = tf.constant([[10,0,0],\n",
        "                      [0,10,0],\n",
        "                      [0,0,10],\n",
        "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
        "\n",
        "temp_v = tf.constant([[   1,0],\n",
        "                      [  10,0],\n",
        "                      [ 100,5],\n",
        "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
        "\n",
        "# This `query` aligns with the second `key`,\n",
        "# so the second `value` is returned.\n",
        "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)\n",
        "\n",
        "\n",
        "\n",
        "# This query aligns with a repeated key (third and fourth), \n",
        "# so all associated values get averaged.\n",
        "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)\n",
        "\n",
        "\n",
        "\n",
        "# This query aligns equally with the first and second key, \n",
        "# so their values get averaged.\n",
        "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)\n",
        "\n",
        "# Pass all queries together\n",
        "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
        "print_out(temp_q, temp_k, temp_v)\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention weights are:\n",
            "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
            "Output is:\n",
            "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n",
            "Attention weights are:\n",
            "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
            "Output is:\n",
            "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n",
            "Attention weights are:\n",
            "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
            "Output is:\n",
            "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n",
            "Attention weights are:\n",
            "tf.Tensor(\n",
            "[[0.  0.  0.5 0.5]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
            "Output is:\n",
            "tf.Tensor(\n",
            "[[550.    5.5]\n",
            " [ 10.    0. ]\n",
            " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwKyAFh_lMgi",
        "outputId": "3acc51d1-72c7-4f05-f4c2-06e2c3198802",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# MULTI HEADED ATTENTION CLASS\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "    \n",
        "    assert d_model % self.num_heads == 0\n",
        "    \n",
        "    self.depth = d_model // self.num_heads\n",
        "    \n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "    \n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "    \n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "    \n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "    \n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "    \n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention, \n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "        \n",
        "    return output, attention_weights\n",
        "\n",
        "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
        "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
        "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
        "out.shape, attn.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrYdjPCHlUe7",
        "outputId": "1ea8d843-822c-4372-f886-881871b6358d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# Point-wise FFN (last layer of each Enc/Dec layer)\n",
        "\n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])\n",
        "\n",
        "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
        "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 50, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyg_T4hfldt_",
        "outputId": "af4da4b5-94ec-432f-cb29-751a81cb2399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# ENCODER LAYER\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    return out2\n",
        "\n",
        "# DECODER LAYER\n",
        "\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        " \n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "    \n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    return out3, attn_weights_block1, attn_weights_block2\n",
        "\n",
        "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
        "\n",
        "sample_encoder_layer_output = sample_encoder_layer(\n",
        "    tf.random.uniform((64, 43, 512)), False, None)\n",
        "\n",
        "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "\n",
        "\n",
        "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
        "\n",
        "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
        "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
        "    False, None, None)\n",
        "\n",
        "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 50, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gjsfkielqt3",
        "outputId": "39932600-0a2e-4af8-fff2-302de5d27620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# GENERAL ENCODER/DECODER FOR TRANSFORMER\n",
        "\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
        "                                            self.d_model)\n",
        "    \n",
        "    \n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "  \n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    \n",
        "    # adding embedding and position encoding.\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "    \n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "    \n",
        "    return x  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "    \n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "    \n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "    \n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "      \n",
        "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "    \n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights\n",
        "\n",
        "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
        "                         dff=2048, input_vocab_size=8500,\n",
        "                         maximum_position_encoding=10000)\n",
        "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
        "\n",
        "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "\n",
        "\n",
        "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
        "                         dff=2048, target_vocab_size=8000,\n",
        "                         maximum_position_encoding=5000)\n",
        "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "output, attn = sample_decoder(temp_input, \n",
        "                              enc_output=sample_encoder_output, \n",
        "                              training=False,\n",
        "                              look_ahead_mask=None, \n",
        "                              padding_mask=None)\n",
        "\n",
        "output.shape, attn['decoder_layer2_block2'].shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 62, 512)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEs0wUHOmC-d"
      },
      "source": [
        "# finally, TRANSFORMER CLASS\n",
        "\n",
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
        "                           input_vocab_size, pe_input, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
        "                           target_vocab_size, pe_target, rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "  def call(self, inp, tar, training, enc_padding_mask, \n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "    # if we wish to retrieve the outputs,this is what we shuld look at!\n",
        "    # we can save it as [target (tar), enc_output]!\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "    # we try to save the encodings here\n",
        "    # maybe something to adjust here: retrieve only the LAST\n",
        "    # in the range of the tokens/enc_outputs\n",
        "    # this is the input though, we may have to ignore the tar_input\n",
        "    # and only save the encodings, then pass ghem to the training step\n",
        "    # and link each encoding to its corresponding tar_real value\n",
        "\n",
        "    \n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "    \n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "    \n",
        "    return enc_output, final_output, attention_weights\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDN77a9BmVuD",
        "outputId": "28e1979b-4823-4191-e099-51312ccbff7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# SETTING HYPERPARAMETERS STEP\n",
        "\n",
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "\n",
        "input_vocab_size = VOCAB_SIZE\n",
        "target_vocab_size = VOCAB_SIZE\n",
        "dropout_rate = 0.1\n",
        "\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    \n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "    \n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "    \n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)\n",
        "\n",
        "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
        "\n",
        "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")\n",
        "\n",
        "# LOSS AND METRICS STEP\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "  \n",
        "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjZSRe9Zmowv"
      },
      "source": [
        "# DEFINE AND CREATE TRANSFORMER MODEL\n",
        "\n",
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size, \n",
        "                          pe_input=input_vocab_size, \n",
        "                          pe_target=target_vocab_size,\n",
        "                          rate=dropout_rate)\n",
        "\n",
        "# CREATE MASKS FOR INPUTS\n",
        "\n",
        "def create_masks(inp, tar):\n",
        "  # Encoder padding mask\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # Used in the 2nd attention block in the decoder.\n",
        "  # This padding mask is used to mask the encoder outputs.\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # Used in the 1st attention block in the decoder.\n",
        "  # It is used to pad and mask future tokens in the input received by \n",
        "  # the decoder.\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  \n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGYRdImem1ga"
      },
      "source": [
        "# DEFINING TRAINING STEP\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
        "# execution. The function specializes to the precise shape of the argument\n",
        "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
        "# batch sizes (the last batch is smaller), use input_signature to specify\n",
        "# more generic shapes.\n",
        "\n",
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
        "]\n",
        "\n",
        "# HERE IS THE TRAINING STEP\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "  \n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, predictions, _ = transformer(inp, tar_inp, \n",
        "                                 True, \n",
        "                                 enc_padding_mask, \n",
        "                                 combined_mask, \n",
        "                                 dec_padding_mask)\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "  \n",
        "  train_loss(loss)\n",
        "  train_accuracy(tar_real, predictions)\n",
        "\n",
        "  return enc_output"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE8VO8QdnMNW",
        "outputId": "f17f412a-040d-44d8-d282-7cf4439e463e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# TRAINING\n",
        "\n",
        "encodings = {}\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "  \n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  \n",
        "  # inp -> asm, tar -> func_names\n",
        "  for (batch, (inp, tar)) in enumerate(dataset):\n",
        "    enc_out = train_step(inp, tar)\n",
        "    # iterate over them, at the last epoch\n",
        "    if epoch == EPOCHS-1:\n",
        "      for n in range(len(tar)):\n",
        "        func = tar[n].ref()\n",
        "        enc = enc_out[n]\n",
        "        if func not in encodings:\n",
        "          encodings[func] = [enc]\n",
        "        else:\n",
        "          encodings[func].append(enc)\n",
        "    \n",
        "    if batch % 50 == 0:\n",
        "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "    \n",
        "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
        "                                                train_loss.result(), \n",
        "                                                train_accuracy.result()))\n",
        "\n",
        "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 9.0225 Accuracy 0.0000\n",
            "Epoch 1 Batch 50 Loss 8.8466 Accuracy 0.0037\n",
            "Epoch 1 Batch 100 Loss 8.5989 Accuracy 0.0069\n",
            "Epoch 1 Batch 150 Loss 8.3796 Accuracy 0.0079\n",
            "Epoch 1 Batch 200 Loss 8.1363 Accuracy 0.0085\n",
            "Epoch 1 Batch 250 Loss 7.8564 Accuracy 0.0088\n",
            "Epoch 1 Batch 300 Loss 7.5425 Accuracy 0.0090\n",
            "Epoch 1 Batch 350 Loss 7.2150 Accuracy 0.0092\n",
            "Epoch 1 Batch 400 Loss 6.9041 Accuracy 0.0093\n",
            "Epoch 1 Loss 6.6364 Accuracy 0.0094\n",
            "Time taken for 1 epoch: 592.9921338558197 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 4.2311 Accuracy 0.0101\n",
            "Epoch 2 Batch 50 Loss 4.1833 Accuracy 0.0101\n",
            "Epoch 2 Batch 100 Loss 4.0916 Accuracy 0.0101\n",
            "Epoch 2 Batch 150 Loss 3.9886 Accuracy 0.0103\n",
            "Epoch 2 Batch 200 Loss 3.8935 Accuracy 0.0104\n",
            "Epoch 2 Batch 250 Loss 3.8121 Accuracy 0.0107\n",
            "Epoch 2 Batch 300 Loss 3.7330 Accuracy 0.0110\n",
            "Epoch 2 Batch 350 Loss 3.6589 Accuracy 0.0112\n",
            "Epoch 2 Batch 400 Loss 3.5942 Accuracy 0.0114\n",
            "Epoch 2 Loss 3.5356 Accuracy 0.0116\n",
            "Time taken for 1 epoch: 579.6810486316681 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 3.0279 Accuracy 0.0123\n",
            "Epoch 3 Batch 50 Loss 2.9810 Accuracy 0.0137\n",
            "Epoch 3 Batch 100 Loss 2.9529 Accuracy 0.0138\n",
            "Epoch 3 Batch 150 Loss 2.9105 Accuracy 0.0140\n",
            "Epoch 3 Batch 200 Loss 2.8808 Accuracy 0.0141\n",
            "Epoch 3 Batch 250 Loss 2.8533 Accuracy 0.0142\n",
            "Epoch 3 Batch 300 Loss 2.8287 Accuracy 0.0143\n",
            "Epoch 3 Batch 350 Loss 2.8018 Accuracy 0.0144\n",
            "Epoch 3 Batch 400 Loss 2.7816 Accuracy 0.0144\n",
            "Epoch 3 Loss 2.7638 Accuracy 0.0145\n",
            "Time taken for 1 epoch: 578.9867408275604 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 2.5028 Accuracy 0.0144\n",
            "Epoch 4 Batch 50 Loss 2.5843 Accuracy 0.0149\n",
            "Epoch 4 Batch 100 Loss 2.5726 Accuracy 0.0151\n",
            "Epoch 4 Batch 150 Loss 2.5468 Accuracy 0.0153\n",
            "Epoch 4 Batch 200 Loss 2.5301 Accuracy 0.0153\n",
            "Epoch 4 Batch 250 Loss 2.5165 Accuracy 0.0155\n",
            "Epoch 4 Batch 300 Loss 2.5064 Accuracy 0.0155\n",
            "Epoch 4 Batch 350 Loss 2.4917 Accuracy 0.0155\n",
            "Epoch 4 Batch 400 Loss 2.4812 Accuracy 0.0155\n",
            "Epoch 4 Loss 2.4712 Accuracy 0.0155\n",
            "Time taken for 1 epoch: 578.5363323688507 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 2.3355 Accuracy 0.0153\n",
            "Epoch 5 Batch 50 Loss 2.3631 Accuracy 0.0158\n",
            "Epoch 5 Batch 100 Loss 2.3538 Accuracy 0.0159\n",
            "Epoch 5 Batch 150 Loss 2.3370 Accuracy 0.0160\n",
            "Epoch 5 Batch 200 Loss 2.3256 Accuracy 0.0161\n",
            "Epoch 5 Batch 250 Loss 2.3189 Accuracy 0.0161\n",
            "Epoch 5 Batch 300 Loss 2.3100 Accuracy 0.0162\n",
            "Epoch 5 Batch 350 Loss 2.2979 Accuracy 0.0162\n",
            "Epoch 5 Batch 400 Loss 2.2905 Accuracy 0.0162\n",
            "Epoch 5 Loss 2.2834 Accuracy 0.0162\n",
            "Time taken for 1 epoch: 579.377435207367 secs\n",
            "\n",
            "Epoch 6 Batch 0 Loss 2.2335 Accuracy 0.0169\n",
            "Epoch 6 Batch 50 Loss 2.2250 Accuracy 0.0164\n",
            "Epoch 6 Batch 100 Loss 2.2191 Accuracy 0.0163\n",
            "Epoch 6 Batch 150 Loss 2.1965 Accuracy 0.0166\n",
            "Epoch 6 Batch 200 Loss 2.1861 Accuracy 0.0166\n",
            "Epoch 6 Batch 250 Loss 2.1769 Accuracy 0.0167\n",
            "Epoch 6 Batch 300 Loss 2.1748 Accuracy 0.0167\n",
            "Epoch 6 Batch 350 Loss 2.1627 Accuracy 0.0168\n",
            "Epoch 6 Batch 400 Loss 2.1601 Accuracy 0.0168\n",
            "Epoch 6 Loss 2.1568 Accuracy 0.0168\n",
            "Time taken for 1 epoch: 578.9245519638062 secs\n",
            "\n",
            "Epoch 7 Batch 0 Loss 2.3268 Accuracy 0.0172\n",
            "Epoch 7 Batch 50 Loss 2.1290 Accuracy 0.0167\n",
            "Epoch 7 Batch 100 Loss 2.1041 Accuracy 0.0169\n",
            "Epoch 7 Batch 150 Loss 2.0927 Accuracy 0.0170\n",
            "Epoch 7 Batch 200 Loss 2.0816 Accuracy 0.0171\n",
            "Epoch 7 Batch 250 Loss 2.0744 Accuracy 0.0172\n",
            "Epoch 7 Batch 300 Loss 2.0713 Accuracy 0.0172\n",
            "Epoch 7 Batch 350 Loss 2.0640 Accuracy 0.0172\n",
            "Epoch 7 Batch 400 Loss 2.0625 Accuracy 0.0172\n",
            "Epoch 7 Loss 2.0592 Accuracy 0.0172\n",
            "Time taken for 1 epoch: 579.6162147521973 secs\n",
            "\n",
            "Epoch 8 Batch 0 Loss 2.0568 Accuracy 0.0166\n",
            "Epoch 8 Batch 50 Loss 2.0282 Accuracy 0.0173\n",
            "Epoch 8 Batch 100 Loss 2.0205 Accuracy 0.0173\n",
            "Epoch 8 Batch 150 Loss 2.0037 Accuracy 0.0175\n",
            "Epoch 8 Batch 200 Loss 1.9965 Accuracy 0.0175\n",
            "Epoch 8 Batch 250 Loss 1.9938 Accuracy 0.0176\n",
            "Epoch 8 Batch 300 Loss 1.9880 Accuracy 0.0176\n",
            "Epoch 8 Batch 350 Loss 1.9820 Accuracy 0.0176\n",
            "Epoch 8 Batch 400 Loss 1.9811 Accuracy 0.0176\n",
            "Epoch 8 Loss 1.9801 Accuracy 0.0176\n",
            "Time taken for 1 epoch: 579.2707834243774 secs\n",
            "\n",
            "Epoch 9 Batch 0 Loss 1.8661 Accuracy 0.0169\n",
            "Epoch 9 Batch 50 Loss 1.9704 Accuracy 0.0175\n",
            "Epoch 9 Batch 100 Loss 1.9551 Accuracy 0.0176\n",
            "Epoch 9 Batch 150 Loss 1.9313 Accuracy 0.0178\n",
            "Epoch 9 Batch 200 Loss 1.9280 Accuracy 0.0178\n",
            "Epoch 9 Batch 250 Loss 1.9211 Accuracy 0.0179\n",
            "Epoch 9 Batch 300 Loss 1.9193 Accuracy 0.0179\n",
            "Epoch 9 Batch 350 Loss 1.9169 Accuracy 0.0179\n",
            "Epoch 9 Batch 400 Loss 1.9129 Accuracy 0.0179\n",
            "Epoch 9 Loss 1.9133 Accuracy 0.0179\n",
            "Time taken for 1 epoch: 578.1380295753479 secs\n",
            "\n",
            "Epoch 10 Batch 0 Loss 1.8794 Accuracy 0.0166\n",
            "Epoch 10 Batch 50 Loss 1.9080 Accuracy 0.0178\n",
            "Epoch 10 Batch 100 Loss 1.8842 Accuracy 0.0180\n",
            "Epoch 10 Batch 150 Loss 1.8612 Accuracy 0.0182\n",
            "Epoch 10 Batch 200 Loss 1.8627 Accuracy 0.0182\n",
            "Epoch 10 Batch 250 Loss 1.8579 Accuracy 0.0182\n",
            "Epoch 10 Batch 300 Loss 1.8501 Accuracy 0.0182\n",
            "Epoch 10 Batch 350 Loss 1.8426 Accuracy 0.0182\n",
            "Epoch 10 Batch 400 Loss 1.8390 Accuracy 0.0182\n",
            "Epoch 10 Loss 1.8348 Accuracy 0.0182\n",
            "Time taken for 1 epoch: 580.316675901413 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H9oQqVd7Dwd",
        "outputId": "5f77019c-72ff-4dfd-e827-c9fcf2681bc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# now getting the encodings\n",
        "# we should have a dictionary of tokens -> list of their encodings\n",
        "\n",
        "print(len(encodings))\n",
        "\n",
        "#output: 28688, it's what we were hoping for\n",
        "# we should have encodings for all the inputs here\n",
        "# by de-tokenizing each element in the numpy array of 'tokens', \n",
        "# we should be able to retrieve the name of each function and its corresponding \n",
        "# econdings.\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqPw6YToJJZn",
        "outputId": "1808368a-496f-4783-abe4-60811b6a30b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "# we exploit tokenizer.decode at next step\n",
        "st = tokenizer.decode([20, 405, 675, 100])\n",
        "print(st)\n",
        "\n",
        "for tokens in encodings:\n",
        "  l = tokens.deref().numpy()\n",
        "  tl = l.tolist()\n",
        "  tl_filtered = [i for i in tl if i != 0 and i < 8100] # removing padding tokens/end tokens\n",
        "  print(tl_filtered)\n",
        "  to_tup = tokenizer.decode(tl_filtered)\n",
        "  print(to_tup)\n",
        "  break"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "JMP t 0x2cpn \n",
            "[382]\n",
            "read\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2y-QcFI_PY0",
        "outputId": "5335a66f-9c49-4839-e9b4-c347bf99c326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# there might be something to adjust here\n",
        "\n",
        "final_encodings = {}\n",
        "\n",
        "for tokens in encodings:\n",
        "  try:\n",
        "    l = tokens.deref().numpy()\n",
        "    tl = l.tolist()\n",
        "    tl_filtered = [i for i in tl if i != 0 and i < 8100] # removing padding tokens/end tokens\n",
        "    to_tup = tokenizer.decode(tl_filtered)\n",
        "    for encoding in encodings[tokens]:\n",
        "      if to_tup in final_encodings:\n",
        "        final_encodings[to_tup].append(encoding.numpy())\n",
        "      else:\n",
        "        final_encodings[to_tup] = [encoding.numpy()]\n",
        "  except:\n",
        "    continue\n",
        "\n",
        "print(len(final_encodings))\n",
        "#print(final_encodings)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3417\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apw7U-DGEqcF",
        "outputId": "93632cbb-7a07-40b4-9704-d972bf2663a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# let's see what we have here\n",
        "i=0\n",
        "for tokens in final_encodings:\n",
        "  print(\"Name: {}, Number of encodings: {}, sample_encoding: {}, shape of encodings: {}\".format(tokens, len(final_encodings[tokens]), final_encodings[tokens][0], final_encodings[tokens][0].shape))\n",
        "  i+=1\n",
        "  if i > 10:\n",
        "    break"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: read, Number of encodings: 190, sample_encoding: [[-0.1227369  -0.03327103  0.02181468 ...  0.04837946 -0.65903664\n",
            "  -0.00180625]\n",
            " [ 0.00363646  0.02754765  0.13562755 ...  0.14458467 -0.9743209\n",
            "  -0.05186015]\n",
            " [-0.10757186 -0.01837586  0.03236189 ...  0.05559143 -0.06685971\n",
            "  -0.08973664]\n",
            " ...\n",
            " [-0.13224244 -0.02054394  0.01954119 ...  0.08991502 -0.8623174\n",
            "  -0.07471956]\n",
            " [-0.06591201  0.13205495  0.19868211 ...  0.2877744  -1.2877147\n",
            "  -0.01385295]\n",
            " [-0.145563    0.00258766  0.05087273 ...  0.1080384  -0.76200557\n",
            "  -0.00084361]], shape of encodings: (100, 128)\n",
            "Name: pars config, Number of encodings: 22, sample_encoding: [[-0.01760408  0.001376    0.05511191 ... -0.43632796 -0.46178713\n",
            "  -0.02689487]\n",
            " [ 0.03794449  0.01742444  0.0730675  ... -0.5672082  -0.5024412\n",
            "   0.01619543]\n",
            " [-0.06039846  0.0084617   0.08171493 ... -0.5129679  -0.56985974\n",
            "  -0.04857072]\n",
            " ...\n",
            " [-0.02678427 -0.09262286  0.05376421 ... -0.23849764 -0.387832\n",
            "  -0.02638234]\n",
            " [ 0.04067817 -0.08805018  0.08574477 ... -0.42602783 -0.48819244\n",
            "  -0.01145373]\n",
            " [ 0.02211898  0.00800319 -0.05233554 ... -0.5575835  -0.51409423\n",
            "   0.02745394]], shape of encodings: (100, 128)\n",
            "Name: set, Number of encodings: 335, sample_encoding: [[-0.3277647   0.04248076  0.06677148 ... -0.07737479 -0.8545438\n",
            "   0.0319973 ]\n",
            " [-0.18306632  0.03257877  0.07170542 ... -0.07878031 -0.73761594\n",
            "   0.07974976]\n",
            " [-0.334566    0.05355542  0.06197247 ... -0.09274623 -0.78728205\n",
            "   0.05048969]\n",
            " ...\n",
            " [-0.29010007  0.0391296   0.0803103  ... -0.09778059 -0.7443706\n",
            "   0.03846856]\n",
            " [-0.29427624  0.07222313  0.08784845 ... -0.08098244 -0.7543709\n",
            "   0.04316425]\n",
            " [-0.11363863  0.0625838   0.07891253 ... -0.11855786 -0.8110499\n",
            "   0.05887836]], shape of encodings: (100, 128)\n",
            "Name: check, Number of encodings: 90, sample_encoding: [[-0.2619144  -0.0062717  -0.21921778 ...  0.07576834 -1.1018966\n",
            "  -0.19823566]\n",
            " [-0.19721805  0.04092717 -0.02972453 ...  0.08330091 -0.19103764\n",
            "  -0.2693858 ]\n",
            " [-0.206241   -0.00447624 -0.20827934 ...  0.04717817 -0.9648535\n",
            "  -0.18577233]\n",
            " ...\n",
            " [-0.23894113 -0.00890005 -0.25944945 ...  0.04087653 -1.0791758\n",
            "  -0.27678147]\n",
            " [-0.1979228   0.04070233 -0.20619798 ...  0.04590128 -0.95114446\n",
            "  -0.18723886]\n",
            " [-0.21247098  0.02663444 -0.21405125 ... -0.01758362 -0.11823873\n",
            "  -0.19293125]], shape of encodings: (100, 128)\n",
            "Name: alloc, Number of encodings: 150, sample_encoding: [[-0.13359113 -0.00482717  0.00993989 ...  0.01374003 -0.6911752\n",
            "  -0.05006472]\n",
            " [-0.05629696 -0.00623062  0.06995803 ...  0.0073637  -0.6958788\n",
            "  -0.04278742]\n",
            " [-0.14128229 -0.0041366   0.0492899  ... -0.01755801 -0.74012196\n",
            "   0.02043219]\n",
            " ...\n",
            " [-0.15522948 -0.01819684  0.0585783  ...  0.00016803 -0.70199895\n",
            "  -0.04606959]\n",
            " [-0.13014579 -0.00210619  0.04816226 ... -0.01094785 -0.7337476\n",
            "  -0.07135723]\n",
            " [-0.14361408 -0.00553157  0.06930082 ... -0.00523881 -0.6760943\n",
            "  -0.06752236]], shape of encodings: (100, 128)\n",
            "Name: do add, Number of encodings: 4, sample_encoding: [[-0.21480125  0.08220628  0.10525662 ...  0.33276114 -0.07552993\n",
            "  -0.01817414]\n",
            " [-0.21709831 -0.01920643 -0.02267286 ...  0.10481178 -0.5813495\n",
            "  -0.10535127]\n",
            " [-0.1786463  -0.02859127 -0.03537146 ...  0.12093807 -0.5694572\n",
            "  -0.1115117 ]\n",
            " ...\n",
            " [-0.2639384  -0.05079654 -0.0311332  ... -0.02274852 -0.05953109\n",
            "  -0.14456007]\n",
            " [-0.2182455  -0.0543343  -0.04329473 ...  0.10484266 -0.57682216\n",
            "  -0.1108871 ]\n",
            " [-0.19766203  0.04203944  0.04172386 ...  0.23266678 -0.8293583\n",
            "  -0.10926268]], shape of encodings: (100, 128)\n",
            "Name: e dbu calendar call send object sync, Number of encodings: 2, sample_encoding: [[-0.3710305  -0.03700859 -0.23364519 ...  0.6730613  -0.57027024\n",
            "  -0.17648831]\n",
            " [-0.01116139 -0.02862026 -0.2063724  ...  0.68255955 -0.5441349\n",
            "  -0.16046269]\n",
            " [-0.40420032 -0.02357974 -0.34407738 ...  0.77419055  0.08615512\n",
            "  -0.15631211]\n",
            " ...\n",
            " [-0.2670023  -0.03298216 -0.2240403  ...  0.63362527 -0.6097756\n",
            "  -0.18139476]\n",
            " [-0.37174132 -0.11958303 -0.41085756 ...  0.65434384 -0.6892561\n",
            "  -0.20673935]\n",
            " [-0.36715898 -0.02110912 -0.36525795 ...  0.6086222  -0.61818826\n",
            "  -0.05367517]], shape of encodings: (100, 128)\n",
            "Name: string To, Number of encodings: 12, sample_encoding: [[-0.5561194  -0.02946186  0.01699764 ...  0.23376006 -0.96009725\n",
            "  -0.03990731]\n",
            " [-0.6157681  -0.0032493  -0.01616919 ...  0.25272453 -0.981331\n",
            "  -0.01387953]\n",
            " [-0.6989545  -0.07263195 -0.0494182  ...  0.23274006 -1.025524\n",
            "  -0.00859287]\n",
            " ...\n",
            " [-0.22140495  0.02308189  0.0504051  ...  0.09456857 -1.0405871\n",
            "  -0.05146273]\n",
            " [-0.6248447  -0.06943025 -0.01573913 ...  0.2380085  -0.9082856\n",
            "  -0.03035981]\n",
            " [-0.63897336 -0.01547896 -0.02449084 ...  0.2447632  -0.78024274\n",
            "  -0.04205057]], shape of encodings: (100, 128)\n",
            "Name: , Number of encodings: 6002, sample_encoding: [[-0.21537593 -0.01339673 -0.00217002 ...  0.15984458 -0.7662183\n",
            "  -0.12187114]\n",
            " [-0.125343    0.00249821  0.03255342 ...  0.03938555 -0.4870824\n",
            "  -0.09709793]\n",
            " [-0.19778349 -0.02311302  0.01473158 ...  0.13679588 -0.65534127\n",
            "  -0.1112369 ]\n",
            " ...\n",
            " [-0.19824344  0.04058348  0.0881376  ...  0.29720783 -1.023769\n",
            "  -0.10327429]\n",
            " [-0.12115633 -0.01620383  0.10259998 ...  0.28161705 -0.96729606\n",
            "  -0.09423712]\n",
            " [-0.15743339  0.01745177  0.02235064 ... -0.00888095 -0.67251784\n",
            "  -0.08406878]], shape of encodings: (100, 128)\n",
            "Name: ag messag deliveri find, Number of encodings: 10, sample_encoding: [[ 0.10982731 -0.03872124 -0.06079046 ...  0.11694601 -0.5787862\n",
            "  -0.1285174 ]\n",
            " [ 0.12516826 -0.01785723 -0.07824045 ... -0.01151665  0.00019094\n",
            "  -0.10025971]\n",
            " [ 0.10670374 -0.02703816 -0.08965544 ...  0.09584697 -0.54947823\n",
            "  -0.02030837]\n",
            " ...\n",
            " [ 0.11902082 -0.01943748 -0.08142279 ...  0.12803656 -0.5489346\n",
            "  -0.09033529]\n",
            " [ 0.16570142 -0.00511245 -0.12476486 ...  0.16797085 -0.00520764\n",
            "  -0.07674067]\n",
            " [ 0.10466449 -0.00244584 -0.12091562 ...  0.15824568 -0.57945764\n",
            "  -0.07579561]], shape of encodings: (100, 128)\n",
            "Name: pn messag, Number of encodings: 23, sample_encoding: [[ 0.07856956 -0.02091765 -0.12524188 ...  0.1691096  -0.5763434\n",
            "  -0.07729708]\n",
            " [ 0.12743416 -0.0301276  -0.10323036 ...  0.1646614   0.00236428\n",
            "  -0.06431052]\n",
            " [ 0.19317454 -0.04334074 -0.05038333 ...  0.01622102 -0.6523221\n",
            "  -0.03157464]\n",
            " ...\n",
            " [ 0.10127031 -0.0560813  -0.098528   ...  0.14697672 -0.5981534\n",
            "  -0.05857568]\n",
            " [ 0.11517902 -0.02932323 -0.10109145 ...  0.01078495 -0.59975094\n",
            "  -0.06415923]\n",
            " [ 0.1573478  -0.00748746 -0.14863618 ...  0.2173067  -0.63521504\n",
            "  -0.05202216]], shape of encodings: (100, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTk-hfXfK4h-"
      },
      "source": [
        "import numpy as np\n",
        "np.savez(open(\"/content/gdrive/My Drive/transformer_enc_out\", \"wb\"), final_encodings)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a56qd0xnXfs"
      },
      "source": [
        "# EVALUATION STEPS\n",
        "\n",
        "def evaluate(inp_sentence):\n",
        "  inp_sentence = preprocess_seq(inp_sentence, False, token_selection)\n",
        "\n",
        "  #inp_sentence = tf.expand_dims(\n",
        "      #START_TOKEN + tokenizer.encode(inp_sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  #encoder_input = tf.expand_dims(inp_sentence, 0)\n",
        "\n",
        "  start_token = [tokenizer.vocab_size]\n",
        "  end_token = [tokenizer.vocab_size + 1]\n",
        "  \n",
        "  # adding the start and end token\n",
        "  inp_sentence = start_token + tokenizer.encode(inp_sentence) + end_token\n",
        "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
        "  \n",
        "  # first word to transformer should be start token\n",
        "\n",
        "  decoder_input = [tokenizer.vocab_size]\n",
        "  output = tf.expand_dims(decoder_input, 0)\n",
        "    \n",
        "  for i in range(MAX_LENGTH):\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "        encoder_input, output)\n",
        "  \n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "    enc_out, predictions, attention_weights = transformer(encoder_input, \n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "    \n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "    \n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if predicted_id == tokenizer.vocab_size+1:\n",
        "      return tf.squeeze(output, axis=0), attention_weights\n",
        "    \n",
        "    # concatentate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "def predict(sentence):\n",
        "  result, attention_weights = evaluate(sentence)\n",
        "  \n",
        "  predicted_sentence = tokenizer.decode([i for i in result \n",
        "                                            if i < tokenizer.vocab_size])  \n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Predicted name: {}'.format(predicted_sentence))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu0iLKDXcrX9",
        "outputId": "1f9f4c2a-5236-4364-b3f6-30cc04420bd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "# test on : LEA RDI 0x11d920 CALL FUN MOV EDI 0x50 MOV RAX qword ptr 0x0011d920 ADD RSP 0x8 LEA RDX 0x11ccc0 CALL FUN RET XOR ECX ECX MOV RSI RAX LEA RSI AgsTimestamp\n",
        "# which really is : ag get type\n",
        "# output: ag messag deliveri get messag -> \"ag get\" gets predicted, with more epochs (20) the output is better (\"ag get type\")\n",
        "print(transformer)\n",
        "predict(\"LEA RDI 0x11d920 CALL FUN MOV EDI 0x50 MOV RAX qword ptr 0x0011d920 ADD RSP 0x8 LEA RDX 0x11ccc0 CALL FUN RET XOR ECX ECX MOV RSI RAX LEA RSI AgsTimestamp\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<__main__.Transformer object at 0x7f3acf73a9e8>\n",
            "Input: LEA RDI 0x11d920 CALL FUN MOV EDI 0x50 MOV RAX qword ptr 0x0011d920 ADD RSP 0x8 LEA RDX 0x11ccc0 CALL FUN RET XOR ECX ECX MOV RSI RAX LEA RSI AgsTimestamp\n",
            "Predicted name: ag messag deliveri get messag\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuRegIE0eX71"
      },
      "source": [
        "# now predicting for the test_samples\n",
        "def evaluate_test(test_seq, test_names):\n",
        "  for idx in range(len(test_seq)):\n",
        "    print('Original Name: {}'.format(test_names[idx]))\n",
        "    predict(test_seq[idx])\n",
        "\n",
        "evaluate_test(test_seq, test_names)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}